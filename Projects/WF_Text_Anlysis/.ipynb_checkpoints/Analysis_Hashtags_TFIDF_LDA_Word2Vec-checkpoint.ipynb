{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Relationships and Topics among Tweets and Facebook Posts Associated with specific banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Deliverables\n",
    "\n",
    "Q1. What financial topics* do consumers discuss on social media and what caused the consumers to post about this topic? \n",
    "   \n",
    ">   Deliverable A - Describe your Approach and Methodology. Include a visual representation of your analytic process flow. \n",
    "   \n",
    ">   Deliverable B - Discuss the data and its relationship to social conversation drivers. \n",
    "\n",
    ">   Deliverable C - Document your code and reference the analytic process flow-diagram from deliverable A. \n",
    "\n",
    "\n",
    "Q2. Are the topics and “substance” consistent across the industry or are they isolated to individual banks? \n",
    "\n",
    ">   Deliverable D - Create a list of topics and substance you found \n",
    "\n",
    ">   Deliverable E - Create a narrative of insights supported by the quantitative results (should include graphs or charts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata:\n",
    "Record Count: 220377\n",
    "\n",
    "Media Type: Facebook & Twitter\n",
    "\n",
    "Timeframe: Twitter data (8/2015) & Facebook data (8/2014 - 8/2015)\n",
    "\n",
    "Scope: Social Media data with query of 4 banks\n",
    "\n",
    "#### Scubbed Data:\n",
    "4 Banks: BankA, BankB, BankC, BankD\n",
    "\n",
    "ADDRESS: All scrubbed addresses are replaced by uppercase ADDRESS. Any occurrence of a lowercase \"address\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "Name: All names have been replaced with the lowercase word \"Name\"\n",
    "Internet links\n",
    "\n",
    "INTERNET: All scrubbed INTERNET references are replaced by uppercase INTERNET. Any occurrence of a lowercase \"internet\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "twit_hndl: All actual twitter handles \"@\" have been replaced with the lowercase abbreviation \"twit_hndl\". All Bank twitter handles have been replaced with the lowercase abbreviation followed by the respectively Bank \"twit_hndl_BankA\" , \"twit_hndl_BankB\"\n",
    "\n",
    "PHONE: All scrubbed phone numbers are replaced by uppercase PHONE. Any occurrence of a lowercase \"phone\" is part of the text and is not a scrubbed replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MediaType</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8/26/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>3 ways the internet of things will change Bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB BankB Name downgrades apple stock to neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB returns to profit on INTERNET/! board2? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB tells advisers to exit paulson hedge fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankC may plead guilty over foreign exchange p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AutoID       Date  Year  Month MediaType  \\\n",
       "0       1  8/26/2015  2015      8   twitter   \n",
       "1       2   8/5/2015  2015      8   twitter   \n",
       "2       3  8/12/2015  2015      8   twitter   \n",
       "3       4   8/5/2015  2015      8   twitter   \n",
       "4       5  8/12/2015  2015      8   twitter   \n",
       "\n",
       "                                            FullText  \n",
       "0  3 ways the internet of things will change Bank...  \n",
       "1  BankB BankB Name downgrades apple stock to neu...  \n",
       "2  BankB returns to profit on INTERNET/! board2? ...  \n",
       "3  BankB tells advisers to exit paulson hedge fun...  \n",
       "4  BankC may plead guilty over foreign exchange p...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2015+Wells+Fargo+Campus+Analytic+Challenge+Dataset.txt', sep='|')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# preprocess the scrubbed strings\n",
    "p0 = re.compile(r'ADDRESS|Name|INTERNET|twit_hndl_?|PHONE')\n",
    "pretext = df['FullText'].map(lambda x: p0.sub('', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text0 = pretext.map(lambda t: t.lower())\n",
    "rawtags1 = text0.map(lambda t: re.findall('\\#\\s\\w+', t))\n",
    "rawtags1 = rawtags1.map(lambda t: [w for w in t if w is not None])\n",
    "rawtags2 = []\n",
    "for t in rawtags1:\n",
    "    if len(t) > 0:\n",
    "        for _ in t:\n",
    "            rawtags2.append(_)\n",
    "rawtags3 = list(set(rawtags2))\n",
    "rawtags4 = dict((a, rawtags2.count(a)) for a in rawtags3)\n",
    "hashtags = sorted(rawtags4.iteritems(), key=lambda (k, v): -v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# bankc', 7003),\n",
       " ('# contest', 4685),\n",
       " ('# getcollegeready', 4626),\n",
       " ('# bankb', 3782),\n",
       " ('# banka', 3721),\n",
       " ('# bankd', 3314),\n",
       " ('# finance', 2680),\n",
       " ('# money', 2082),\n",
       " ('# goldmansachs', 1990),\n",
       " ('# wallstreet', 1987),\n",
       " ('# banksters', 1948),\n",
       " ('# economics', 1924),\n",
       " ('# hsbc', 1922),\n",
       " ('# usbank', 1922),\n",
       " ('# morganstanley', 1920),\n",
       " ('# federalreserve', 1915),\n",
       " ('# classwarfare', 1912),\n",
       " ('# financialterrorists', 1910),\n",
       " ('# stocks', 513),\n",
       " ('# business', 488),\n",
       " ('# news', 469),\n",
       " ('# c', 390),\n",
       " ('# realestate', 367),\n",
       " ('# stock', 359),\n",
       " ('# investment', 341),\n",
       " ('# banking', 339),\n",
       " ('# forex', 334),\n",
       " ('# share', 332),\n",
       " ('# acn', 329),\n",
       " ('# smallbiz', 301)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the tweets, the hastags \"contest\" and \"getcollegeready\" always come together, and this campaign certainly draw much attention as the bank would expect. So this campaign is a highlight among the others. Other than that, my first impression is that when people talk about banks, they care about keeping their money safe and their investments increasingly growing up (by talking about ecnomy, stocks, federa reserve, forex, small biz), and there seems be an emotion about the banks as the opposite side of normal ones. I would have expected many hashtags on the services or other campaigns, but we need further tagging process to figure out how these information is related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do some viz about dist of hastags among different banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data Grouped By Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [3, ways, the, internet, of, things, will, cha...\n",
       "1    [bankb, bankb, downgrades, apple, stock, to, n...\n",
       "2    [bankb, returns, to, profit, on, board2, t, 95...\n",
       "3    [bankb, tells, advisers, to, exit, paulson, he...\n",
       "4    [bankc, may, plead, guilty, over, foreign, exc...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pretext.map(lambda x: x.lower())\n",
    "text = text.map(lambda x: re.split('\\W+|_+', x, flags=re.IGNORECASE))\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indA = ['banka' in t for t in text]\n",
    "indB = ['bankb' in t for t in text]\n",
    "indC = ['bankc' in t for t in text]\n",
    "indD = ['bankd' in t for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [, ways, the, internet, , things, will, change...\n",
       "1    [bankb, bankb, downgrades, apple, stock, , neu...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-complie patterns to speed up\n",
    "p1 = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\")  # remove retweet or via mark\n",
    "p2 = re.compile(r\"@\\w+\")  # remove at mark\n",
    "p3 = re.compile(r\"^[0-9]+$\")  # remove pure numbers\n",
    "p4 = re.compile(r\"http\\w+\")  # remove http address\n",
    "p5 = re.compile(r\"^\\s+|\\s+$\")  # remove space\n",
    "p6 = re.compile(r\"^\\w*(\\w)(\\1){2,}\\w*&\")  # remove repetitive letters\n",
    "p7 = re.compile(r\"^\\w{2}$\")  # remove words with only two letters\n",
    "text = text.map(lambda x: [p1.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p2.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p3.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p4.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p5.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p6.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p7.sub(\"\", t) for t in x])\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ways, internet, things, change, 1u5ad88, inte...\n",
       "1    [downgrades, apple, stock, neutral, anticipate...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = pd.read_csv('stopwords.txt')\n",
    "outwords = ['banka','bankb','bankc','bankd','bank','twit','hndl','lol','hey','make','made','name','don','bit','uhijre','ret','bankac','resp','ers','today','ift','dlvr','plc','goo','man','banke','bankds']\n",
    "\n",
    "def rmStopWord(wlist):\n",
    "    return [w for w in wlist if not (w == '' or w in stopwords.values or w in outwords)]     \n",
    "\n",
    "posttext = text.map(lambda x: rmStopWord(x))\n",
    "posttext.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn From TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = post_text.map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=1)\n",
    "Xtfidf = tfidfvec.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawk', 12.609952352206955),\n",
       " (u'zbnlwm1sov5vz', 12.609952352206955),\n",
       " (u'bestcustomerservice', 12.609952352206955),\n",
       " (u'wednesd', 12.609952352206955),\n",
       " (u'33gdrk', 12.609952352206955),\n",
       " (u'kurringaibankd2015', 12.609952352206955),\n",
       " (u'wannaaaa', 12.609952352206955),\n",
       " (u'1j9qzei', 12.609952352206955),\n",
       " (u'aresearch', 12.609952352206955),\n",
       " (u'mumfordandsons', 12.609952352206955)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = dict(zip(tfidfvec.get_feature_names(), tfidfvec.idf_))\n",
    "top10 = sorted(idf.iteritems(), key=lambda x: -x[1])[:10]\n",
    "top10                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LDA Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-34c425706ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodelA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_ldamodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodelB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_ldamodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodelC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_ldamodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-34c425706ab2>\u001b[0m in \u001b[0;36mgenerate_ldamodel\u001b[0;34m(indArray, min_df, num_topics)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_ldamodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindArray\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcountvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mid2words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import gensim\n",
    "\n",
    "def generate_ldamodel(indArray ,min_df=1, num_topics=10):\n",
    "    countvec = CountVectorizer(min_df=min_df)\n",
    "    X = countvec.fit_transform(indArray)\n",
    "    corpus = countvec.get_feature_names()\n",
    "    id2words = dict((v, k) for k, v in countvec.vocabulary_.iteritems())\n",
    "    corpus_gensim = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus_gensim, id2word=id2words, num_topics=10, update_every=1, chunksize=1000, passes=1)\n",
    "    return ldamodel\n",
    "\n",
    "modelA = generate_ldamodel(lines[indA])\n",
    "modelB = generate_ldamodel(lines[indB])\n",
    "modelC = generate_ldamodel(lines[indC])\n",
    "modelD = generate_ldamodel(lines[indD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.016*family + 0.015*support + 0.011*paid + 0.010*youre + 0.010*program + 0.010*week + 0.009*million + 0.009*great + 0.008*work + 0.008*gonna',\n",
       " u'0.061*center + 0.017*account + 0.015*day + 0.015*time + 0.014*worst + 0.013*guys + 0.013*open + 0.013*shit + 0.013*tickets + 0.010*teller',\n",
       " u'0.032*good + 0.020*wow + 0.017*financial + 0.012*community + 0.011*group + 0.009*things + 0.009*big + 0.009*set + 0.009*home + 0.009*years',\n",
       " u'0.037*customer + 0.035*service + 0.021*usbank + 0.018*hsbc + 0.018*working + 0.017*great + 0.015*happy + 0.015*night + 0.013*team + 0.011*share',\n",
       " u'0.042*business + 0.021*banking + 0.019*rebanke + 0.013*fund + 0.012*buy + 0.011*building + 0.011*investment + 0.010*commercial + 0.009*insurance + 0.008*find',\n",
       " u'0.054*money + 0.041*photo + 0.033*shared + 0.029*finance + 0.023*company + 0.022*goldmansachs + 0.022*banksters + 0.022*economics + 0.022*federalreserve + 0.022*wallstreet',\n",
       " u'0.041*contest + 0.040*getcollegeready + 0.017*whats + 0.015*ready + 0.015*sucks + 0.015*care + 0.014*win + 0.014*information + 0.014*saturday + 0.013*college',\n",
       " u'0.057*account + 0.039*card + 0.028*money + 0.023*credit + 0.016*check + 0.014*pay + 0.013*cash + 0.013*dont + 0.012*banks + 0.011*debit',\n",
       " u'0.031*call + 0.023*phone + 0.018*customers + 0.016*love + 0.013*day + 0.013*stop + 0.011*give + 0.011*called + 0.011*fuck + 0.010*payment',\n",
       " u'0.031*mortgage + 0.024*home + 0.020*loan + 0.014*number + 0.013*market + 0.013*stock + 0.012*car + 0.011*fucking + 0.010*report + 0.010*economy']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.072*account + 0.031*money + 0.022*dont + 0.018*day + 0.013*time + 0.012*guys + 0.011*deposit + 0.011*told + 0.011*fees + 0.010*line',\n",
       " u'0.053*photo + 0.038*hsbc + 0.024*atm + 0.024*work + 0.014*money + 0.013*family + 0.012*month + 0.012*love + 0.012*night + 0.011*times',\n",
       " u'0.064*card + 0.025*account + 0.025*call + 0.022*credit + 0.018*debit + 0.016*number + 0.013*fuck + 0.012*phone + 0.012*open + 0.011*fraud',\n",
       " u'0.019*mortgage + 0.017*year + 0.015*loan + 0.014*financial + 0.012*pay + 0.012*cards + 0.011*settlement + 0.010*send + 0.010*thing + 0.009*million',\n",
       " u'0.027*service + 0.025*customer + 0.022*check + 0.019*great + 0.017*years + 0.016*banks + 0.013*banking + 0.013*day + 0.012*job + 0.012*customers',\n",
       " u'0.037*stadium + 0.022*home + 0.014*charlotte + 0.013*working + 0.013*ass + 0.012*aint + 0.012*panthers + 0.011*game + 0.010*run + 0.010*hate',\n",
       " u'0.041*morganstanley + 0.016*free + 0.015*rating + 0.011*weekend + 0.011*buy + 0.011*car + 0.011*put + 0.011*savings + 0.010*minutes + 0.009*gave',\n",
       " u'0.065*money + 0.045*shared + 0.042*finance + 0.037*economics + 0.037*goldmansachs + 0.037*usbank + 0.037*wallstreet + 0.037*banksters + 0.036*classwarfare + 0.036*federalreserve',\n",
       " u'0.017*called + 0.017*people + 0.015*goldman + 0.015*money + 0.014*business + 0.013*sachs + 0.012*yall + 0.011*building + 0.011*give + 0.010*house',\n",
       " u'0.030*chicago + 0.025*marathon + 0.015*lot + 0.014*watch + 0.012*app + 0.012*friends + 0.010*ready + 0.009*neutral + 0.009*apple + 0.009*learn']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.081*goldmansachs + 0.079*morganstanley + 0.025*oil + 0.024*price + 0.017*service + 0.017*customer + 0.013*manager + 0.011*deal + 0.010*good + 0.008*click',\n",
       " u'0.022*trader + 0.016*tom + 0.015*case + 0.013*banking + 0.010*upgraded + 0.009*libor + 0.009*billion + 0.008*taking + 0.008*court + 0.008*business',\n",
       " u'0.117*photo + 0.067*money + 0.056*banksters + 0.056*economics + 0.055*classwarfare + 0.055*financialterrorists + 0.051*giannis + 0.051*theodwridis + 0.019*group + 0.010*time',\n",
       " u'0.087*wallstreet + 0.020*stock + 0.014*sell + 0.011*buy + 0.009*downgraded + 0.008*wetf + 0.008*stocks + 0.006*money + 0.006*office + 0.006*future',\n",
       " u'0.067*federalreserve + 0.049*credit + 0.046*goldman + 0.044*sachs + 0.032*card + 0.019*world + 0.012*cards + 0.012*finance + 0.010*free + 0.010*money',\n",
       " u'0.019*pay + 0.019*financial + 0.015*million + 0.014*years + 0.013*banks + 0.013*business + 0.012*wow + 0.012*global + 0.011*street + 0.009*charges',\n",
       " u'0.013*people + 0.011*big + 0.011*dont + 0.011*hold + 0.010*work + 0.008*customers + 0.008*call + 0.007*deals + 0.007*year + 0.007*banks',\n",
       " u'0.063*hsbc + 0.060*finance + 0.059*rating + 0.059*usbank + 0.034*buy + 0.023*neutral + 0.015*reiterated + 0.011*target + 0.008*real + 0.008*raised',\n",
       " u'0.040*account + 0.016*card + 0.012*open + 0.011*cash + 0.010*time + 0.007*product + 0.007*experience + 0.007*rebanke + 0.007*banking + 0.006*store',\n",
       " u'0.138*shared + 0.020*hall + 0.014*energy + 0.013*report + 0.011*change + 0.011*cost + 0.010*president + 0.010*trillion + 0.010*climate + 0.009*research']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelC.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.054*rating + 0.053*asset + 0.043*money + 0.037*finance + 0.031*hsbc + 0.030*banksters + 0.030*wallstreet + 0.030*economics + 0.030*usbank + 0.029*federalreserve',\n",
       " u'0.037*goldmansachs + 0.019*stockport + 0.012*world + 0.012*investment + 0.008*raised + 0.007*ranked + 0.007*usa + 0.007*oil + 0.007*long + 0.007*win',\n",
       " u'0.019*company + 0.014*check + 0.014*data + 0.012*young + 0.012*banking + 0.011*real + 0.010*good + 0.010*police + 0.010*deposit + 0.009*fund',\n",
       " u'0.040*stockport + 0.040*overweight + 0.027*neutral + 0.013*trading + 0.013*trade + 0.012*report + 0.010*security + 0.008*breach + 0.007*news + 0.007*analyst',\n",
       " u'0.072*account + 0.030*money + 0.016*people + 0.015*dont + 0.012*cash + 0.009*funds + 0.009*open + 0.009*banks + 0.009*time + 0.008*deposit',\n",
       " u'0.024*group + 0.016*job + 0.016*service + 0.013*manager + 0.012*support + 0.011*cut + 0.010*work + 0.009*love + 0.009*customer + 0.009*home',\n",
       " u'0.108*street + 0.105*vote + 0.105*main + 0.104*mission + 0.063*business + 0.055*small + 0.053*program + 0.053*apply + 0.053*full + 0.053*learn',\n",
       " u'0.043*managers + 0.039*photo + 0.033*card + 0.017*credit + 0.009*debit + 0.008*free + 0.008*time + 0.008*banks + 0.007*city + 0.007*find',\n",
       " u'0.019*big + 0.016*community + 0.015*price + 0.015*target + 0.013*mortgage + 0.009*global + 0.009*jobs + 0.009*day + 0.009*gold + 0.008*market',\n",
       " u'0.054*financial + 0.045*management + 0.044*wealth + 0.042*advisers + 0.037*shared + 0.010*energy + 0.009*year + 0.009*cards + 0.008*top + 0.007*sales']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelD.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Similars words from Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2A = gensim.models.Word2Vec(text[indA], min_count=1, size=40)\n",
    "model2B = gensim.models.Word2Vec(text[indB], min_count=1, size=40)\n",
    "model2C = gensim.models.Word2Vec(text[indC], min_count=1, size=40)\n",
    "model2D = gensim.models.Word2Vec(text[indD], min_count=1, size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_words = ['getcollegeready', 'finance', 'wallstreet', 'economics', 'federalreserve']\n",
    "neg_words = ['classwarfare', 'financialterrorists', 'finance', 'wallstreet', 'economics', 'federalreserve', 'banksters']\n",
    "\n",
    "synonymA = model2A.most_similar(positive=['banka'])\n",
    "synonymB = model2B.most_similar(positive=['bankb'])\n",
    "synonymC = model2C.most_similar(positive=['bankc'])\n",
    "synonymD = model2D.most_similar(positive=['bankd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('husbandmaterial', 0.5419613122940063),\n",
       " ('shrieking', 0.5392065048217773),\n",
       " ('4iugnnqps', 0.47520220279693604),\n",
       " ('ludicrous', 0.47099435329437256),\n",
       " ('3y7uax', 0.46934011578559875),\n",
       " ('yourhomeyourway', 0.4658353924751282),\n",
       " ('batess', 0.46269187331199646),\n",
       " ('julia', 0.4623016119003296),\n",
       " ('bzy0fk', 0.4602036774158478),\n",
       " ('comercal', 0.45838963985443115)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymA\n",
    "# 1.bank teller at BankA just flirted with me and then followed up by giving me a blue raspberry dum-dum.\n",
    "# # husbandmaterial# orhethinksimalittlegirl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('palmers', 0.5909887552261353),\n",
       " ('achieva', 0.5908536314964294),\n",
       " ('problam', 0.5905898809432983),\n",
       " ('kidos', 0.5829063653945923),\n",
       " ('salesmen', 0.5633691549301147),\n",
       " ('trials', 0.5237843990325928),\n",
       " ('magical', 0.5028483867645264),\n",
       " ('liberated', 0.5003407597541809),\n",
       " ('zombies', 0.4987490773200989),\n",
       " ('99problems', 0.4951059818267822)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tapered', 0.529935359954834),\n",
       " ('devi', 0.5161897540092468),\n",
       " ('chinastocks', 0.5062400102615356),\n",
       " ('teachmehowtoadult', 0.4992290139198303),\n",
       " ('influencing', 0.4850664734840393),\n",
       " ('dako', 0.47909513115882874),\n",
       " ('systemaicmedicalprogram', 0.454127699136734),\n",
       " ('derulo', 0.45412763953208923),\n",
       " ('establishes', 0.45327693223953247),\n",
       " ('integrati', 0.4498327672481537)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eatin', 0.6147010326385498),\n",
       " ('hiphopheads', 0.5570492148399353),\n",
       " ('providian', 0.5414141416549683),\n",
       " ('ahahaha', 0.5339089632034302),\n",
       " ('a1zp48', 0.5333604216575623),\n",
       " ('barlcays', 0.5299626588821411),\n",
       " ('1lbf07r', 0.5296684503555298),\n",
       " ('lmss', 0.527097225189209),\n",
       " ('edh', 0.5142173767089844),\n",
       " ('ubs32', 0.49940818548202515)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the record, the Word2Vec is not giving out really crucial information on the topic, but it could help as a good supplement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
