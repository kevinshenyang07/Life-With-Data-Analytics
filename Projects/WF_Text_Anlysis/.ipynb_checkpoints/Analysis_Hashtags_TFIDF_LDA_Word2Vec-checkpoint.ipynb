{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Relationships and Topics among Tweets and Facebook Posts Associated with specific banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Deliverables\n",
    "\n",
    "Q1. What financial topics* do consumers discuss on social media and what caused the consumers to post about this topic? \n",
    "   \n",
    ">   Deliverable A - Describe your Approach and Methodology. Include a visual representation of your analytic process flow. \n",
    "   \n",
    ">   Deliverable B - Discuss the data and its relationship to social conversation drivers. \n",
    "\n",
    ">   Deliverable C - Document your code and reference the analytic process flow-diagram from deliverable A. \n",
    "\n",
    "\n",
    "Q2. Are the topics and “substance” consistent across the industry or are they isolated to individual banks? \n",
    "\n",
    ">   Deliverable D - Create a list of topics and substance you found \n",
    "\n",
    ">   Deliverable E - Create a narrative of insights supported by the quantitative results (should include graphs or charts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata:\n",
    "Record Count: 220377\n",
    "\n",
    "Media Type: Facebook & Twitter\n",
    "\n",
    "Timeframe: Twitter data (8/2015) & Facebook data (8/2014 - 8/2015)\n",
    "\n",
    "Scope: Social Media data with query of 4 banks\n",
    "\n",
    "#### Scubbed Data:\n",
    "4 Banks: BankA, BankB, BankC, BankD\n",
    "\n",
    "ADDRESS: All scrubbed addresses are replaced by uppercase ADDRESS. Any occurrence of a lowercase \"address\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "Name: All names have been replaced with the lowercase word \"Name\"\n",
    "Internet links\n",
    "\n",
    "INTERNET: All scrubbed INTERNET references are replaced by uppercase INTERNET. Any occurrence of a lowercase \"internet\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "twit_hndl: All actual twitter handles \"@\" have been replaced with the lowercase abbreviation \"twit_hndl\". All Bank twitter handles have been replaced with the lowercase abbreviation followed by the respectively Bank \"twit_hndl_BankA\" , \"twit_hndl_BankB\"\n",
    "\n",
    "PHONE: All scrubbed phone numbers are replaced by uppercase PHONE. Any occurrence of a lowercase \"phone\" is part of the text and is not a scrubbed replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype has the wrong size, try recompiling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa44af558781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtslib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot import name '\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# hack but overkill to use re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/numpy.pxd\u001b[0m in \u001b[0;36minit pandas.tslib (pandas/tslib.c:102684)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype has the wrong size, try recompiling"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MediaType</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8/26/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>3 ways the internet of things will change Bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB BankB Name downgrades apple stock to neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB returns to profit on INTERNET/! board2? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB tells advisers to exit paulson hedge fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankC may plead guilty over foreign exchange p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AutoID       Date  Year  Month MediaType  \\\n",
       "0       1  8/26/2015  2015      8   twitter   \n",
       "1       2   8/5/2015  2015      8   twitter   \n",
       "2       3  8/12/2015  2015      8   twitter   \n",
       "3       4   8/5/2015  2015      8   twitter   \n",
       "4       5  8/12/2015  2015      8   twitter   \n",
       "\n",
       "                                            FullText  \n",
       "0  3 ways the internet of things will change Bank...  \n",
       "1  BankB BankB Name downgrades apple stock to neu...  \n",
       "2  BankB returns to profit on INTERNET/! board2? ...  \n",
       "3  BankB tells advisers to exit paulson hedge fun...  \n",
       "4  BankC may plead guilty over foreign exchange p...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2015+Wells+Fargo+Campus+Analytic+Challenge+Dataset.txt', sep='|')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# preprocess the scrubbed strings\n",
    "p0 = re.compile('ADDRESS|Name|INTERNET|twit_hndl_?|PHONE')\n",
    "pretext = df['FullText'].map(lambda x: p0.sub(' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name#', 8010),\n",
       " ('getcollegeready#', 4365),\n",
       " ('bankb#', 2769),\n",
       " ('bankd#', 2526),\n",
       " ('bankc#', 2449),\n",
       " ('finance#', 2290),\n",
       " ('internet#', 2084),\n",
       " ('money#', 2010),\n",
       " ('goldmansachs#', 1967),\n",
       " ('wallstreet#', 1946),\n",
       " ('banksters#', 1924),\n",
       " ('usbank#', 1915),\n",
       " ('hsbc#', 1914),\n",
       " ('economics#', 1914),\n",
       " ('federalreserve#', 1910),\n",
       " ('financialterrorists#', 1910),\n",
       " ('classwarfare#', 1906),\n",
       " ('morganstanley#', 1905),\n",
       " ('twit_hndl#', 1442),\n",
       " ('twit_hndl_banka#', 1298)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text0 = pretext.map(lambda t: t.lower().split())\n",
    "rawtags1 = text0.map(lambda t: [re.search('\\w+#\\B', w) for w in t])\n",
    "rawtags1 = rawtags1.map(lambda t: [w.group(0) for w in t if w is not None])\n",
    "rawtags2 = []\n",
    "for t in rawtags1:\n",
    "    if len(t) > 0:\n",
    "        for _ in t:\n",
    "            rawtags2.append(_)\n",
    "rawtags3 = list(set(rawtags2))\n",
    "rawtags4 = dict((a, rawtags2.count(a)) for a in rawtags3)\n",
    "hashtags = sorted(rawtags4.iteritems(), key=lambda (k, v): -v)\n",
    "hashtags[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data Grouped By Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [3, ways, the, internet, of, things, will, cha...\n",
       "1    [bankb, bankb, name, downgrades, apple, stock,...\n",
       "2    [bankb, returns, to, profit, on, internet, boa...\n",
       "3    [bankb, tells, advisers, to, exit, paulson, he...\n",
       "4    [bankc, may, plead, guilty, over, foreign, exc...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pretext.map(lambda x: x.lower())\n",
    "text = text.map(lambda x: re.split('\\W+|_+', x, flags=re.IGNORECASE))\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indA = ['banka' in t for t in text]\n",
    "indB = ['bankb' in t for t in text]\n",
    "indC = ['bankc' in t for t in text]\n",
    "indD = ['bankd' in t for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [, ways, the, internet, of, things, will, chan...\n",
       "1    [bankb, bankb, name, downgrades, apple, stock,...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-complie patterns to speed up\n",
    "p1 = re.compile(\"(RT|via)((?:\\b\\W*@\\w+)+)\")\n",
    "p2 = re.compile(\"@\\w+\")\n",
    "p3 = re.compile(\"[0-9]+\")\n",
    "p4 = re.compile(\"http\\w+\")\n",
    "p5 = re.compile(\"^\\s+|\\s+$\")\n",
    "p6 = re.compile(\"^\\w*(\\w)(\\1){2,}\\w*&\")\n",
    "text = text.map(lambda x: [p1.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p2.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p3.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p4.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p5.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p6.sub(\"\", t) for t in x])\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ways, internet, things, change, tt, uad, inte...\n",
       "1    [downgrades, apple, stock, neutral, anticipate...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords1 = pd.read_csv('stopwords.txt')\n",
    "stopwords2 = ['banka','bankb','bankc','bankd','bank','hndl','twit','lol','hey','make','name','don','bit','uhijre','ret','bankac','resp','ers','er','today','ift','dlvr','plc','goo','man','banke','bankds']\n",
    "\n",
    "def rmStopWord(wlist):\n",
    "    return [w for w in wlist if not (w == '' or w in stopwords1.values or w in stopwords2)]     \n",
    "\n",
    "text = text.map(lambda x: rmStopWord(x))\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn From TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = text.map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=1)\n",
    "Xtfidf = tfidfvec.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LDA Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import gensim\n",
    "\n",
    "def generate_ldamodel(indArray ,min_df=1, num_topics=10):\n",
    "    countvec = CountVectorizer(min_df=min_df)\n",
    "    X = countvec.fit_transform(indArray)\n",
    "    corpus = countvec.get_feature_names()\n",
    "    id2words = dict((v, k) for k, v in countvec.vocabulary_.iteritems())\n",
    "    corpus_gensim = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus_gensim, id2word=id2words, num_topics=10, update_every=1, chunksize=1000, passes=1)\n",
    "    return ldamodel\n",
    "\n",
    "modelA = generate_ldamodel(lines[indA])\n",
    "modelB = generate_ldamodel(lines[indB])\n",
    "modelC = generate_ldamodel(lines[indC])\n",
    "modelD = generate_ldamodel(lines[indD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.045*card + 0.036*photo + 0.030*shared + 0.025*credit + 0.019*business + 0.018*economics + 0.015*debit + 0.013*night + 0.011*working + 0.011*money',\n",
       " u'0.038*money + 0.023*finance + 0.017*hsbc + 0.016*cash + 0.012*made + 0.012*days + 0.011*fb + 0.011*buy + 0.011*information + 0.010*card',\n",
       " u'0.045*contest + 0.044*getcollegeready + 0.018*love + 0.015*school + 0.014*awesome + 0.011*long + 0.011*set + 0.011*win + 0.011*story + 0.010*ready',\n",
       " u'0.024*goldmansachs + 0.024*banksters + 0.024*morganstanley + 0.023*wallstreet + 0.023*financialterrorists + 0.023*classwarfare + 0.021*wow + 0.020*mortgage + 0.017*home + 0.016*fund',\n",
       " u'0.068*center + 0.056*internet + 0.014*tickets + 0.014*financial + 0.013*pm + 0.012*tomorrow + 0.011*email + 0.011*college + 0.009*coming + 0.009*philadelphia',\n",
       " u'0.055*internet + 0.050*ly + 0.012*home + 0.012*loan + 0.011*market + 0.011*loans + 0.010*fuck + 0.010*community + 0.009*program + 0.009*world',\n",
       " u'0.077*internet + 0.018*guys + 0.016*worst + 0.013*support + 0.012*team + 0.011*great + 0.010*job + 0.010*arena + 0.010*company + 0.009*sucks',\n",
       " u'0.064*account + 0.025*customer + 0.023*service + 0.021*check + 0.019*dont + 0.018*money + 0.013*usbank + 0.012*time + 0.011*customers + 0.010*deposit',\n",
       " u'0.039*call + 0.035*phone + 0.019*shit + 0.016*give + 0.015*stop + 0.013*giving + 0.012*start + 0.012*called + 0.012*banker + 0.010*im',\n",
       " u'0.037*internet + 0.021*banking + 0.018*banks + 0.016*federalreserve + 0.012*family + 0.012*years + 0.011*open + 0.011*whats + 0.010*mortgage + 0.010*online']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.050*photo + 0.033*check + 0.015*people + 0.014*line + 0.013*business + 0.012*branch + 0.012*teller + 0.011*hate + 0.011*hold + 0.011*pm',\n",
       " u'0.043*internet + 0.041*finance + 0.041*stadium + 0.036*hsbc + 0.035*financialterrorists + 0.016*charlotte + 0.014*team + 0.013*panthers + 0.012*game + 0.011*watch',\n",
       " u'0.045*internet + 0.037*morganstanley + 0.025*home + 0.018*mortgage + 0.018*buy + 0.014*pay + 0.014*loan + 0.012*free + 0.011*st + 0.011*times',\n",
       " u'0.026*chicago + 0.022*marathon + 0.016*goldman + 0.013*sachs + 0.012*yall + 0.011*day + 0.011*internet + 0.011*video + 0.010*tickets + 0.009*shit',\n",
       " u'0.020*yo + 0.018*fuck + 0.016*rating + 0.014*internet + 0.010*work + 0.009*post + 0.009*rebanke + 0.009*america + 0.009*shit + 0.009*overdraft',\n",
       " u'0.041*card + 0.026*service + 0.025*customer + 0.018*credit + 0.018*time + 0.016*years + 0.016*debit + 0.015*account + 0.014*banking + 0.013*worst',\n",
       " u'0.083*money + 0.044*shared + 0.034*goldmansachs + 0.034*wallstreet + 0.034*usbank + 0.034*federalreserve + 0.034*classwarfare + 0.029*banksters + 0.016*giannis + 0.016*theodwridis',\n",
       " u'0.088*internet + 0.013*made + 0.012*center + 0.012*morning + 0.011*school + 0.010*street + 0.010*building + 0.010*financial + 0.007*top + 0.007*ceo',\n",
       " u'0.046*internet + 0.022*ly + 0.015*tt + 0.015*fb + 0.013*stock + 0.011*house + 0.011*dollars + 0.011*getcollegeready + 0.010*pack + 0.009*apple',\n",
       " u'0.065*account + 0.030*money + 0.021*economics + 0.020*dont + 0.013*atm + 0.013*good + 0.012*cash + 0.011*give + 0.011*card + 0.011*people']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.036*buy + 0.029*internet + 0.016*stock + 0.013*work + 0.011*people + 0.010*big + 0.008*money + 0.008*real + 0.008*good + 0.008*interest',\n",
       " u'0.100*internet + 0.015*ly + 0.015*banking + 0.012*wow + 0.010*city + 0.008*global + 0.007*report + 0.007*ceo + 0.007*tower + 0.007*plaza',\n",
       " u'0.054*card + 0.051*credit + 0.027*account + 0.013*cards + 0.011*banks + 0.010*rebanke + 0.008*cash + 0.007*pay + 0.007*time + 0.007*put',\n",
       " u'0.078*goldmansachs + 0.022*service + 0.020*customer + 0.013*manager + 0.012*free + 0.011*account + 0.010*customers + 0.007*call + 0.007*mortgage + 0.007*days',\n",
       " u'0.162*shared + 0.082*wallstreet + 0.081*economics + 0.013*open + 0.009*ny + 0.007*international + 0.007*house + 0.006*data + 0.006*night + 0.005*start',\n",
       " u'0.045*sachs + 0.030*goldman + 0.030*internet + 0.018*ly + 0.018*group + 0.017*trader + 0.012*tom + 0.012*gl + 0.012*case + 0.010*buy',\n",
       " u'0.076*internet + 0.056*hsbc + 0.053*federalreserve + 0.053*rating + 0.035*tt + 0.021*neutral + 0.016*price + 0.016*oil + 0.015*hall + 0.013*reiterated',\n",
       " u'0.054*internet + 0.023*world + 0.012*street + 0.012*business + 0.011*ly + 0.011*china + 0.010*president + 0.009*job + 0.008*wall + 0.008*years',\n",
       " u'0.055*internet + 0.017*ly + 0.016*pay + 0.014*target + 0.014*million + 0.013*business + 0.012*fund + 0.011*sell + 0.011*services + 0.010*charges',\n",
       " u'0.106*photo + 0.067*money + 0.059*finance + 0.052*banksters + 0.051*usbank + 0.049*morganstanley + 0.049*classwarfare + 0.049*financialterrorists + 0.047*theodwridis + 0.047*giannis']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelC.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.064*internet + 0.028*ly + 0.015*transfer + 0.015*young + 0.015*news + 0.014*data + 0.013*target + 0.012*million + 0.012*investment + 0.011*price',\n",
       " u'0.061*account + 0.033*card + 0.020*neutral + 0.020*credit + 0.012*deposit + 0.011*fb + 0.010*open + 0.010*manager + 0.009*debit + 0.008*life',\n",
       " u'0.019*dont + 0.015*people + 0.014*pay + 0.013*great + 0.012*check + 0.009*years + 0.008*call + 0.008*give + 0.008*whats + 0.007*banks',\n",
       " u'0.074*internet + 0.049*financial + 0.049*asset + 0.043*stockport + 0.038*managers + 0.037*advisers + 0.035*photo + 0.028*overweight + 0.009*trading + 0.008*report',\n",
       " u'0.069*money + 0.032*shared + 0.032*finance + 0.027*hsbc + 0.027*banksters + 0.026*wallstreet + 0.026*economics + 0.026*morganstanley + 0.026*classwarfare + 0.026*financialterrorists',\n",
       " u'0.064*rating + 0.058*internet + 0.040*tt + 0.018*reiterated + 0.009*yum + 0.007*house + 0.007*trade + 0.007*robbery + 0.007*billion + 0.006*downgraded',\n",
       " u'0.043*internet + 0.015*stock + 0.013*community + 0.012*banks + 0.011*support + 0.009*security + 0.009*police + 0.009*free + 0.008*ceo + 0.008*insurance',\n",
       " u'0.061*management + 0.051*wealth + 0.034*usbank + 0.020*internet + 0.014*job + 0.011*big + 0.011*time + 0.010*cards + 0.010*day + 0.007*find',\n",
       " u'0.041*goldmansachs + 0.040*federalreserve + 0.025*group + 0.017*giannis + 0.017*theodwridis + 0.013*internet + 0.013*mortgage + 0.010*market + 0.008*state + 0.008*banking',\n",
       " u'0.147*internet + 0.090*street + 0.088*vote + 0.088*main + 0.087*mission + 0.053*business + 0.046*small + 0.045*program + 0.044*learn + 0.044*full']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelD.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Similars words from Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
