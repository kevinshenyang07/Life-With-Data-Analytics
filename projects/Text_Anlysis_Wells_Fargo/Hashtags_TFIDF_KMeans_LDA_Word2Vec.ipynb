{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Relationships and Topics among Tweets and Facebook Posts Associated with specific banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Deliverables\n",
    "\n",
    "Q1. What financial topics* do consumers discuss on social media and what caused the consumers to post about this topic? \n",
    "   \n",
    ">   Deliverable A - Describe your Approach and Methodology. Include a visual representation of your analytic process flow. \n",
    "   \n",
    ">   Deliverable B - Discuss the data and its relationship to social conversation drivers. \n",
    "\n",
    ">   Deliverable C - Document your code and reference the analytic process flow-diagram from deliverable A. \n",
    "\n",
    "\n",
    "Q2. Are the topics and “substance” consistent across the industry or are they isolated to individual banks? \n",
    "\n",
    ">   Deliverable D - Create a list of topics and substance you found \n",
    "\n",
    ">   Deliverable E - Create a narrative of insights supported by the quantitative results (should include graphs or charts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata:\n",
    "Record Count: 220377\n",
    "\n",
    "Media Type: Facebook & Twitter\n",
    "\n",
    "Timeframe: Twitter data (8/2015) & Facebook data (8/2014 - 8/2015)\n",
    "\n",
    "Scope: Social Media data with query of 4 banks\n",
    "\n",
    "#### Scubbed Data:\n",
    "4 Banks: BankA, BankB, BankC, BankD\n",
    "\n",
    "ADDRESS: All scrubbed addresses are replaced by uppercase ADDRESS. Any occurrence of a lowercase \"address\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "Name: All names have been replaced with the lowercase word \"Name\"\n",
    "Internet links\n",
    "\n",
    "INTERNET: All scrubbed INTERNET references are replaced by uppercase INTERNET. Any occurrence of a lowercase \"internet\" is part of the text and is not a scrubbed replacement.\n",
    "\n",
    "twit_hndl: All actual twitter handles \"@\" have been replaced with the lowercase abbreviation \"twit_hndl\". All Bank twitter handles have been replaced with the lowercase abbreviation followed by the respectively Bank \"twit_hndl_BankA\" , \"twit_hndl_BankB\"\n",
    "\n",
    "PHONE: All scrubbed phone numbers are replaced by uppercase PHONE. Any occurrence of a lowercase \"phone\" is part of the text and is not a scrubbed replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AutoID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MediaType</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8/26/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>3 ways the internet of things will change Bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB BankB Name downgrades apple stock to neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB returns to profit on INTERNET/! board2? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankB tells advisers to exit paulson hedge fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8/12/2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter</td>\n",
       "      <td>BankC may plead guilty over foreign exchange p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AutoID       Date  Year  Month MediaType  \\\n",
       "0       1  8/26/2015  2015      8   twitter   \n",
       "1       2   8/5/2015  2015      8   twitter   \n",
       "2       3  8/12/2015  2015      8   twitter   \n",
       "3       4   8/5/2015  2015      8   twitter   \n",
       "4       5  8/12/2015  2015      8   twitter   \n",
       "\n",
       "                                            FullText  \n",
       "0  3 ways the internet of things will change Bank...  \n",
       "1  BankB BankB Name downgrades apple stock to neu...  \n",
       "2  BankB returns to profit on INTERNET/! board2? ...  \n",
       "3  BankB tells advisers to exit paulson hedge fun...  \n",
       "4  BankC may plead guilty over foreign exchange p...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2015+Wells+Fargo+Campus+Analytic+Challenge+Dataset.txt', sep='|')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# preprocess the scrubbed strings\n",
    "p0 = re.compile(r'ADDRESS|Name|INTERNET|twit_hndl_?|PHONE')\n",
    "pretext = df['FullText'].map(lambda x: p0.sub('', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text0 = pretext.map(lambda t: t.lower())\n",
    "rawtags1 = text0.map(lambda t: re.findall('\\#\\s\\w+', t))\n",
    "rawtags1 = rawtags1.map(lambda t: [w for w in t if w is not None])\n",
    "rawtags2 = []\n",
    "for t in rawtags1:\n",
    "    if len(t) > 0:\n",
    "        for _ in t:\n",
    "            rawtags2.append(_)\n",
    "rawtags3 = list(set(rawtags2))\n",
    "rawtags4 = dict((a, rawtags2.count(a)) for a in rawtags3)\n",
    "hashtags = sorted(rawtags4.iteritems(), key=lambda (k, v): -v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# bankc', 7003),\n",
       " ('# contest', 4685),\n",
       " ('# getcollegeready', 4626),\n",
       " ('# bankb', 3782),\n",
       " ('# banka', 3721),\n",
       " ('# bankd', 3314),\n",
       " ('# finance', 2680),\n",
       " ('# money', 2082),\n",
       " ('# goldmansachs', 1990),\n",
       " ('# wallstreet', 1987),\n",
       " ('# banksters', 1948),\n",
       " ('# economics', 1924),\n",
       " ('# hsbc', 1922),\n",
       " ('# usbank', 1922),\n",
       " ('# morganstanley', 1920),\n",
       " ('# federalreserve', 1915),\n",
       " ('# classwarfare', 1912),\n",
       " ('# financialterrorists', 1910),\n",
       " ('# stocks', 513),\n",
       " ('# business', 488),\n",
       " ('# news', 469),\n",
       " ('# c', 390),\n",
       " ('# realestate', 367),\n",
       " ('# stock', 359),\n",
       " ('# investment', 341),\n",
       " ('# banking', 339),\n",
       " ('# forex', 334),\n",
       " ('# share', 332),\n",
       " ('# acn', 329),\n",
       " ('# smallbiz', 301)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the tweets, the hastags \"contest\" and \"getcollegeready\" always come together, and this campaign certainly draw much attention as the bank would expect. So this campaign is a highlight among the others. Other than that, my first impression is that when people talk about banks, they care about keeping their money safe and their investments increasingly growing up (by talking about ecnomy, stocks, federa reserve, forex, small biz), and there seems be an emotion about the banks as the opposite side of normal ones. I would have expected many hashtags on the services or other campaigns, but we need further tagging process to figure out how these information is related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do some viz about dist of hastags among different banks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data Grouped By Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [3, ways, the, internet, of, things, will, cha...\n",
       "1    [bankb, bankb, downgrades, apple, stock, to, n...\n",
       "2    [bankb, returns, to, profit, on, board2, t, 95...\n",
       "3    [bankb, tells, advisers, to, exit, paulson, he...\n",
       "4    [bankc, may, plead, guilty, over, foreign, exc...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pretext.map(lambda x: x.lower())\n",
    "text = text.map(lambda x: re.split('\\W+|_+', x, flags=re.IGNORECASE))\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indA = ['banka' in t for t in text]\n",
    "indB = ['bankb' in t for t in text]\n",
    "indC = ['bankc' in t for t in text]\n",
    "indD = ['bankd' in t for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [, ways, the, internet, , things, will, change...\n",
       "1    [bankb, bankb, downgrades, apple, stock, , neu...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-complie patterns to speed up\n",
    "p1 = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\")  # remove retweet or via mark\n",
    "p2 = re.compile(r\"@\\w+\")  # remove at mark\n",
    "p3 = re.compile(r\"^[0-9]+$\")  # remove pure numbers\n",
    "p4 = re.compile(r\"http\\w+\")  # remove http address\n",
    "p5 = re.compile(r\"^\\s+|\\s+$\")  # remove space\n",
    "p6 = re.compile(r\"^\\w*(\\w)(\\1){2,}\\w*&\")  # remove repetitive letters\n",
    "p7 = re.compile(r\"^\\w{2}$\")  # remove words with only two letters\n",
    "text = text.map(lambda x: [p1.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p2.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p3.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p4.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p5.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p6.sub(\"\", t) for t in x])\n",
    "text = text.map(lambda x: [p7.sub(\"\", t) for t in x])\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ways, internet, things, change, bankb, bankc,...\n",
       "1    [bankb, bankb, downgrades, apple, stock, neutr...\n",
       "Name: FullText, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = pd.read_csv('stopwords.txt')\n",
    "outwords = ['bank','twit','hndl','lol','hey','make','made','name','don','bit','uhijre','ret','bankac','resp','ers','today','ift','dlvr','plc','goo','man','banke','bankds']\n",
    "\n",
    "def rmStopWord(wlist):\n",
    "    return [w for w in wlist if not (w == '' or w in stopwords.values or w in outwords)]     \n",
    "\n",
    "posttext = text.map(lambda x: rmStopWord(x))\n",
    "posttext.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn From TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepareLines(wlist):\n",
    "    wlist = [w for w in wlist if not w in ['banka', 'bankb', 'bankc', 'bankd']]\n",
    "    return ' '.join(wlist)\n",
    "\n",
    "lines = posttext.map(lambda x: prepareLines(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=1)\n",
    "Xtfidf = tfidfvec.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawk', 12.609952352206955),\n",
       " (u'zbnlwm1sov5vz', 12.609952352206955),\n",
       " (u'bestcustomerservice', 12.609952352206955),\n",
       " (u'wednesd', 12.609952352206955),\n",
       " (u'33gdrk', 12.609952352206955),\n",
       " (u'kurringaibankd2015', 12.609952352206955),\n",
       " (u'wannaaaa', 12.609952352206955),\n",
       " (u'1j9qzei', 12.609952352206955),\n",
       " (u'aresearch', 12.609952352206955),\n",
       " (u'mumfordandsons', 12.609952352206955)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = dict(zip(tfidfvec.get_feature_names(), tfidfvec.idf_))\n",
    "top10 = sorted(idf.iteritems(), key=lambda x: -x[1])[:10]\n",
    "top10                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still lots of noises there since TFIDF tend to over-estimate the importance of very rare words. We would just keep it and move on to the next method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As k-means is optimizing a non-convex objective function, it will likely end up in a local optimum. Trying with different parameters is neccessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=6, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "true_k = 6\n",
    "km_model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "km_model.fit(Xtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "contest, getcollegeready, vote, street, money, main, business, mission, card, photo\n",
      "\n",
      "Cluster 1:\n",
      "pay, mortgage, home, loan, million, settlement, loans, billion, student, settle\n",
      "\n",
      "Cluster 2:\n",
      "assistance, called, additional, trouble, provided, happy, future, call, needed, information\n",
      "\n",
      "Cluster 3:\n",
      "account, assist, happened, numbers, money, open, checking, dont, tweet, card\n",
      "\n",
      "Cluster 4:\n",
      "management, asset, stockport, wealth, advisers, managers, financial, cheshire, ftse, independent\n",
      "\n",
      "Cluster 5:\n",
      "msg, dir, zip, phone, follow, call, account, number, requested, concerns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km_model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidfvec.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print \"Cluster {}:\".format(i)\n",
    "    kws = []\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        kws.append(terms[ind])\n",
    "    print \"{}\".format(', '.join(kws)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the clusters\n",
    "\n",
    "As a quick shot, K-Means works better than I have expected. The clusters are clearly divided and the term with highest frequency is exactly the summary of the cluster. As indicated ahead, the clusters are:\n",
    "\n",
    "1. contest - tweets about the 'get college ready' contest.\n",
    "2. pay - tweets about paying mortgages, loans including student loans.\n",
    "3. assistance - tweets about getting assitance from the bank by calls, getting information and get all of trouble.\n",
    "4. management - tweets about asset management with financial advisors \n",
    "5. msg - tweets about providing informations to the others\n",
    "\n",
    "Amazing right?!\n",
    "\n",
    "To determine wether there are differences of topics among different banks, we could divide the dataset and apply TFIDF and K-Means Method respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LDA Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import gensim\n",
    "\n",
    "def generate_ldamodel(indArray ,min_df=1, num_topics=10):\n",
    "    countvec = CountVectorizer(min_df=min_df)\n",
    "    X = countvec.fit_transform(indArray)\n",
    "    corpus = countvec.get_feature_names()\n",
    "    id2words = dict((v, k) for k, v in countvec.vocabulary_.iteritems())\n",
    "    corpus_gensim = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus_gensim, id2word=id2words, num_topics=10, update_every=1, chunksize=1000, passes=1)\n",
    "    return ldamodel\n",
    "\n",
    "modelA = generate_ldamodel(lines[indA])\n",
    "modelB = generate_ldamodel(lines[indB])\n",
    "modelC = generate_ldamodel(lines[indC])\n",
    "modelD = generate_ldamodel(lines[indD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.061*money + 0.059*bankb + 0.047*banka + 0.039*photo + 0.031*shared + 0.031*bankc + 0.021*goldmansachs + 0.021*morganstanley + 0.021*wallstreet + 0.021*financialterrorists',\n",
       " u'0.106*banka + 0.053*account + 0.037*card + 0.025*money + 0.022*credit + 0.022*dont + 0.015*usbank + 0.015*pay + 0.011*business + 0.011*loan',\n",
       " u'0.115*banka + 0.025*home + 0.022*business + 0.017*mortgage + 0.016*working + 0.014*wow + 0.009*building + 0.009*market + 0.009*loans + 0.009*stock',\n",
       " u'0.127*banka + 0.026*customer + 0.024*service + 0.013*phone + 0.013*work + 0.013*time + 0.013*rebanke + 0.012*good + 0.010*company + 0.008*put',\n",
       " u'0.111*banka + 0.024*call + 0.015*job + 0.014*night + 0.014*give + 0.014*great + 0.012*fund + 0.012*whats + 0.011*team + 0.011*share',\n",
       " u'0.099*banka + 0.027*bankd + 0.026*finance + 0.024*account + 0.019*check + 0.019*federalreserve + 0.017*cash + 0.014*guys + 0.012*fees + 0.011*atm',\n",
       " u'0.108*banka + 0.067*center + 0.015*buy + 0.014*tickets + 0.008*philadelphia + 0.007*friday + 0.007*read + 0.007*services + 0.007*wont + 0.007*free',\n",
       " u'0.141*banka + 0.035*contest + 0.034*getcollegeready + 0.025*banksters + 0.025*economics + 0.016*bankc + 0.014*love + 0.013*bankb + 0.013*bankd + 0.010*event',\n",
       " u'0.124*banka + 0.014*family + 0.014*fuck + 0.014*financial + 0.013*shit + 0.012*year + 0.010*banks + 0.010*photos + 0.009*awesome + 0.009*start',\n",
       " u'0.114*banka + 0.017*worst + 0.016*day + 0.014*bankb + 0.013*tomorrow + 0.011*sucks + 0.010*information + 0.010*report + 0.009*group + 0.009*big']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.113*bankb + 0.022*customer + 0.021*service + 0.020*chicago + 0.016*marathon + 0.013*put + 0.010*sachs + 0.009*hate + 0.008*worst + 0.008*business',\n",
       " u'0.160*bankb + 0.041*stadium + 0.037*economics + 0.017*buy + 0.015*charlotte + 0.013*rating + 0.011*stock + 0.010*dollars + 0.009*apple + 0.009*things',\n",
       " u'0.068*bankb + 0.036*wallstreet + 0.018*check + 0.017*great + 0.015*job + 0.014*days + 0.013*banks + 0.012*week + 0.012*game + 0.012*credit',\n",
       " u'0.078*bankc + 0.053*banka + 0.045*bankb + 0.044*bankd + 0.041*money + 0.035*finance + 0.032*shared + 0.030*hsbc + 0.030*goldmansachs + 0.030*usbank',\n",
       " u'0.117*bankb + 0.070*money + 0.038*account + 0.031*bankd + 0.028*banksters + 0.025*banka + 0.014*dont + 0.012*shit + 0.011*fuck + 0.011*ass',\n",
       " u'0.079*bankb + 0.061*card + 0.031*account + 0.025*call + 0.017*debit + 0.015*number + 0.014*called + 0.012*pay + 0.012*check + 0.012*free',\n",
       " u'0.109*bankb + 0.023*banka + 0.014*atm + 0.012*account + 0.011*time + 0.011*people + 0.009*love + 0.009*guys + 0.009*rebanke + 0.008*line',\n",
       " u'0.102*bankb + 0.048*photo + 0.015*mortgage + 0.012*pay + 0.011*family + 0.011*company + 0.010*watch + 0.009*settlement + 0.009*loan + 0.008*deal',\n",
       " u'0.077*bankb + 0.018*account + 0.016*panthers + 0.015*center + 0.012*police + 0.012*close + 0.011*night + 0.011*tickets + 0.009*ready + 0.009*checking',\n",
       " u'0.104*bankb + 0.018*home + 0.017*day + 0.015*time + 0.013*good + 0.010*work + 0.010*find + 0.009*morning + 0.009*years + 0.008*financial']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.148*shared + 0.101*bankc + 0.012*fund + 0.010*real + 0.009*settlement + 0.008*analyst + 0.007*government + 0.007*million + 0.007*mortgage + 0.007*court',\n",
       " u'0.090*bankc + 0.066*money + 0.063*hsbc + 0.060*economics + 0.012*street + 0.011*banking + 0.009*cut + 0.008*hold + 0.007*business + 0.007*banks',\n",
       " u'0.091*bankc + 0.022*service + 0.021*customer + 0.012*year + 0.012*team + 0.010*tower + 0.010*plaza + 0.008*trading + 0.007*data + 0.007*added',\n",
       " u'0.096*bankc + 0.025*financial + 0.015*wow + 0.014*good + 0.013*job + 0.011*loan + 0.009*student + 0.008*services + 0.008*home + 0.008*business',\n",
       " u'0.110*bankc + 0.040*card + 0.039*credit + 0.013*big + 0.011*account + 0.010*cards + 0.009*rebanke + 0.008*open + 0.007*dont + 0.007*worst',\n",
       " u'0.145*bankc + 0.125*photo + 0.030*theodwridis + 0.030*giannis + 0.025*money + 0.022*world + 0.019*oil + 0.018*price + 0.017*hall + 0.015*group',\n",
       " u'0.131*bankc + 0.062*banka + 0.059*banksters + 0.059*rating + 0.056*finance + 0.035*buy + 0.023*neutral + 0.014*reiterated + 0.009*president + 0.009*city',\n",
       " u'0.103*bankc + 0.025*time + 0.018*account + 0.016*pay + 0.014*stock + 0.013*day + 0.013*work + 0.009*running + 0.009*free + 0.009*people',\n",
       " u'0.117*bankc + 0.031*goldman + 0.029*sachs + 0.011*trader + 0.009*trillion + 0.009*sell + 0.009*target + 0.008*tom + 0.008*years + 0.008*case',\n",
       " u'0.081*bankb + 0.080*bankd + 0.077*bankc + 0.057*wallstreet + 0.057*goldmansachs + 0.056*usbank + 0.055*federalreserve + 0.055*morganstanley + 0.055*financialterrorists + 0.055*classwarfare']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelC.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.094*bankd + 0.016*price + 0.016*target + 0.008*real + 0.008*state + 0.007*list + 0.006*earns + 0.006*bad + 0.006*year + 0.005*profit',\n",
       " u'0.104*bankd + 0.029*card + 0.017*credit + 0.013*time + 0.009*fraud + 0.008*world + 0.008*debit + 0.008*center + 0.008*cards + 0.007*bankb',\n",
       " u'0.099*bankd + 0.029*hsbc + 0.029*goldmansachs + 0.017*money + 0.013*account + 0.012*manager + 0.012*people + 0.011*check + 0.011*community + 0.010*trade',\n",
       " u'0.105*street + 0.102*vote + 0.102*main + 0.101*mission + 0.060*business + 0.054*small + 0.051*program + 0.051*apply + 0.051*full + 0.051*learn',\n",
       " u'0.147*bankd + 0.053*rating + 0.037*photo + 0.030*overweight + 0.020*neutral + 0.018*group + 0.015*reiterated + 0.013*stock + 0.011*yum + 0.009*energy',\n",
       " u'0.105*bankd + 0.046*asset + 0.042*management + 0.041*stockport + 0.015*transfer + 0.008*support + 0.008*news + 0.007*investment + 0.006*talk + 0.006*find',\n",
       " u'0.074*bankd + 0.047*bankb + 0.041*money + 0.036*banka + 0.034*finance + 0.028*banksters + 0.027*economics + 0.027*morganstanley + 0.027*classwarfare + 0.026*financialterrorists',\n",
       " u'0.079*bankc + 0.060*financial + 0.049*wealth + 0.045*advisers + 0.042*bankd + 0.041*shared + 0.033*usbank + 0.016*young + 0.013*giannis + 0.013*theodwridis',\n",
       " u'0.118*bankd + 0.055*account + 0.036*managers + 0.012*service + 0.012*money + 0.011*deposit + 0.010*banking + 0.010*rebanke + 0.009*open + 0.009*raised',\n",
       " u'0.110*bankd + 0.020*day + 0.016*work + 0.013*job + 0.009*life + 0.008*post + 0.008*pay + 0.008*whats + 0.007*big + 0.007*love']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelD.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Similars words from Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2A = gensim.models.Word2Vec(posttext[indA], min_count=5, size=200, window=10, sample=1e-3)\n",
    "model2B = gensim.models.Word2Vec(posttext[indB], min_count=5, size=200, window=10, sample=1e-3)\n",
    "model2C = gensim.models.Word2Vec(posttext[indC], min_count=5, size=200, window=10, sample=1e-3)\n",
    "model2D = gensim.models.Word2Vec(posttext[indD], min_count=5, size=200, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_words = ['getcollegeready', 'finance', 'wallstreet', 'economics', 'federalreserve']\n",
    "neg_words = ['classwarfare', 'financialterrorists', 'finance', 'wallstreet', 'economics', 'federalreserve', 'banksters']\n",
    "\n",
    "synonymA = model2A.most_similar(positive=['banka'])\n",
    "synonymB = model2B.most_similar(positive=['bankb'])\n",
    "synonymC = model2C.most_similar(positive=['bankc'])\n",
    "synonymD = model2D.most_similar(positive=['bankd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rips', 0.41391533613204956),\n",
       " ('legbanke', 0.4094012677669525),\n",
       " ('rejects', 0.4015510082244873),\n",
       " ('voltas', 0.3973686993122101),\n",
       " ('controls', 0.3954523801803589),\n",
       " ('diverse', 0.39538949728012085),\n",
       " ('laundered', 0.39101722836494446),\n",
       " ('racked', 0.3908594846725464),\n",
       " ('priority', 0.3881450593471527),\n",
       " ('bankb', 0.386219322681427)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banka', 0.40592920780181885),\n",
       " ('flirting', 0.40380358695983887),\n",
       " ('time', 0.40342628955841064),\n",
       " ('deactivating', 0.3880406320095062),\n",
       " ('onna', 0.38779035210609436),\n",
       " ('money', 0.3877057433128357),\n",
       " ('momma', 0.38676372170448303),\n",
       " ('finest', 0.38422441482543945),\n",
       " ('bees', 0.3828417658805847),\n",
       " ('bday', 0.3821169137954712)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ally', 0.4044133424758911),\n",
       " ('joy', 0.4033159017562866),\n",
       " ('mobi', 0.3953450620174408),\n",
       " ('brad', 0.3903713822364807),\n",
       " ('tradehero', 0.3739902675151825),\n",
       " ('americans', 0.36382365226745605),\n",
       " ('democrat', 0.35904332995414734),\n",
       " ('mac', 0.35303962230682373),\n",
       " ('bust', 0.35217738151550293),\n",
       " ('plutonomy', 0.3496810793876648)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('starwood', 0.3895378112792969),\n",
       " ('format', 0.3509492874145508),\n",
       " ('a', 0.3482472598552704),\n",
       " ('slices', 0.34181737899780273),\n",
       " ('crush', 0.33760976791381836),\n",
       " ('viking', 0.3316380977630615),\n",
       " ('lifes', 0.33112823963165283),\n",
       " ('vietnamese', 0.3307943344116211),\n",
       " ('refunding', 0.32516494393348694),\n",
       " ('somethin', 0.32326266169548035)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the record, the Word2Vec is not giving out explainable information on the topic, and it is very hard to get the best result since the output is very sensitive to the parameters. But it could help as a good supplement. Here are several interesting findings:\n",
    "\n",
    "1. banka and bankb are more related than other two banks since in banka's synonyms appear bankb, and vice versa.\n",
    "2. In banka's synonyms, legbanke aprears approximately 80 times. Let's go back to the tweets and find the original sentence: \"they keep updating me on what i no longer legbanke owe them. Name. we see u BankA thugs!\" Seems that the word should be legally, and the engineers subsititute the 'ally' with 'banke'. Also, lots of negative words for banka.\n",
    "3. In bankc's synonyms, two words catch my eyes: democrat and tradehero. It seems that many people use tradehero to buy shares of bankc and bankd.\n",
    "4. In bankd's synonyms, 'viking' and 'vikings stadium' is mentioned a lot, gotcha U.S.Bank.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
