{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEDLINE Papers Network Analysis\n",
    "\n",
    "Every year, MELINE(Medical Literature Analysis and Retrieval System Online) would publish a sample of acamdemic papers covering the life sciences and medcine. \n",
    "\n",
    "You can find the MEDLINE dataset here: [ftp://ftp.nlm.nih.gov/nlmdata/sample/medline/](ftp://ftp.nlm.nih.gov/nlmdata/sample/medline/). There are eight separate XML files with the total size of 928m. \n",
    "\n",
    "In this notebook, I'm going to investigate three topics about the network analysis:\n",
    "\n",
    "[Part1: Community Detection](#Part1: Community Detection)\n",
    "\n",
    "Considering the languages used, which group of users is more likely to publish papers together? Is this true that the smaller the language group is, the higher the clustering effect would occur?\n",
    "\n",
    "[Part2: Co-occurence of Attributes](#Part2: Co-occurence of Attributes)\n",
    "\n",
    "\n",
    "\n",
    "Considering the descriptions and keywords of the papers, what combinations of descriptions or keywords are more likely to appear together?\n",
    "\n",
    "[Part3: Link Prediction](#Part3: Link Prediction)\n",
    "\n",
    "Although this is not a classic social network, can we build a model to predict waht combinations of authors are more likely to publish a paper together(having an edge)?\n",
    "\n",
    "Dependencies: \n",
    "\n",
    "networkX. Pure python implementation of graph algorithms, works fine with this dataset, but if you are analyzing bigger graphs, the scalability could be a problem. iGraph is not better but GraphX would be a good alternative, coming with Pregel API is even better.\n",
    "\n",
    "H2O. Very fast data processing and model training thanks to its structure of compressing the data and store it on the JVM heap. The documentaion is complex but it is promising and offers H2O with hadoop/Spark to scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "% matplotlib inline\n",
    "\n",
    "# name your own file path\n",
    "dirpath = \"/Users/apple/Downloads/datasets/aas/medline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import codecs\n",
    "\n",
    "# use iterparse to extract info from xml files\n",
    "def extract_papers(fs):\n",
    "    '''\n",
    "    parameter: xml files\n",
    "    return: dictionary of papers\n",
    "            key: PMID\n",
    "            value: list of authors\n",
    "                   list of language used\n",
    "                   list of descriptions\n",
    "                   list of keywords\n",
    "    '''\n",
    "    papers = {}\n",
    "    for f in fs:\n",
    "        with codecs.open(f, 'r') as fi:\n",
    "            path = []\n",
    "            for event, elem in ET.iterparse(fi, events=(\"start\", \"end\")):\n",
    "                if event == \"start\":\n",
    "                    path.append(elem.tag)\n",
    "                    if elem.tag == 'PMID':\n",
    "                        k = elem.text\n",
    "                        papers[k] = {'auth':[], 'lang':[], 'description':[], 'keyword':[]}\n",
    "                    elif 'Author' in path:\n",
    "                        if elem.tag == 'LastName':\n",
    "                            papers[k]['auth'].append([elem.text])\n",
    "                        if elem.tag == 'ForeName' and elem.text is not None:\n",
    "                            papers[k]['auth'][-1].append(elem.text)\n",
    "                    elif elem.tag == 'Language' and elem.text is not None:\n",
    "                        langs = elem.text\n",
    "                        if len(langs)%3 != 0:\n",
    "                            print '{0}: incorrect/no languages -> {1}'.format(k, langs)\n",
    "                        else:\n",
    "                            for i in range(len(langs)/3):\n",
    "                                papers[k]['lang'].append(langs[3*i:(3*i+3)])\n",
    "                    elif elem.tag == 'DescriptorName':\n",
    "                        papers[k]['description'].append(elem.text)\n",
    "                    elif elem.tag == 'Keyword':\n",
    "                        papers[k]['keyword'].append(elem.text)\n",
    "                elif event == \"end\":\n",
    "                    path.pop()\n",
    "                elem.clear()\n",
    "    for k,v in papers.iteritems():\n",
    "        if len(v['auth']) > 0:\n",
    "            papers[k]['auth'] = [' '.join(auth) for auth in papers[k]['auth'] if auth[0] is not None]\n",
    "    return {k:v for k,v in papers.iteritems() if len(papers[k]['auth']) > 0}\n",
    "\n",
    "\n",
    "files = []\n",
    "for i in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']:\n",
    "    fn = dirpath+'medsamp2016'+i+'.xml'\n",
    "    files.append(fn)\n",
    "    \n",
    "papers = extract_papers(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('23515729',\n",
       "  {'auth': [\"Mont'Alverne\",\n",
       "    'Galdino Lara Maia',\n",
       "    'Pinheiro Marcela Cunha',\n",
       "    u'Levy C\\xedntia Souto',\n",
       "    'Vasconcelos Glauber Gean de',\n",
       "    u'Souza Neto Jo\\xe3o David de',\n",
       "    u'Mej\\xeda Juan Alberto Cosquillo'],\n",
       "   'description': ['Cardiomyopathy, Dilated',\n",
       "    'Cross-Sectional Studies',\n",
       "    'Exercise Test',\n",
       "    'Female',\n",
       "    'Heart Transplantation',\n",
       "    'Humans',\n",
       "    'Intraoperative Complications',\n",
       "    'Male',\n",
       "    'Middle Aged',\n",
       "    'Postoperative Complications',\n",
       "    'Reference Values',\n",
       "    'Retrospective Studies',\n",
       "    'Tachycardia',\n",
       "    'Time Factors',\n",
       "    'Treatment Outcome',\n",
       "    'Ventricular Dysfunction, Right'],\n",
       "   'keyword': [],\n",
       "   'lang': ['eng', 'por']}),\n",
       " ('14360229',\n",
       "  {'auth': ['HOHORST H J'],\n",
       "   'description': ['Antibodies',\n",
       "    'Antigens',\n",
       "    'Bacteria',\n",
       "    'Blood Group Antigens',\n",
       "    'Escherichia',\n",
       "    'Humans',\n",
       "    'O Antigens',\n",
       "    'Salmonella'],\n",
       "   'keyword': ['ANTIGENS AND ANTIBODIES',\n",
       "    'BLOOD GROUPS',\n",
       "    'ESCHERICHIA',\n",
       "    'SALMONELLA'],\n",
       "   'lang': ['eng', 'ger']})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the result\n",
    "# filter the result with more than one language used\n",
    "[(k,v) for k,v in papers.iteritems() if len(v['lang']) > 1][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1: Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 476558\n",
      "Number of edges: 1090012\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "\n",
    "def create_graph():\n",
    "    '''\n",
    "    return:\n",
    "    a graph with author as node\n",
    "    coauthorship as edge\n",
    "    language used as attribute\n",
    "    '''\n",
    "    G = nx.Graph()\n",
    "    for v in papers.itervalues():\n",
    "        langs = v['lang']\n",
    "        auths = v['auth']\n",
    "        if len(auths) > 1:\n",
    "            G.add_nodes_from(auths)\n",
    "            for comb in combinations(auths, 2):\n",
    "                for lang in langs:\n",
    "                    G.add_edge(comb[0], comb[1], lang=lang)\n",
    "        else:\n",
    "            G.add_node(auths[0])\n",
    "    print 'Number of nodes: {}'.format(G.number_of_nodes())\n",
    "    print 'Number of edges: {}'.format(G.number_of_edges())\n",
    "    return G\n",
    "\n",
    "G_auth = create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('eng', 397167),\n",
      " ('fre', 16274),\n",
      " ('ger', 14503),\n",
      " ('spa', 9819),\n",
      " ('rus', 9669),\n",
      " ('ita', 7879),\n",
      " ('pol', 6307),\n",
      " ('chi', 6161),\n",
      " ('jpn', 4757),\n",
      " ('por', 3675),\n",
      " ('cze', 2441),\n",
      " ('hun', 1546),\n",
      " ('rum', 1321),\n",
      " ('dut', 1199),\n",
      " ('bul', 842),\n",
      " ('und', 818),\n",
      " ('swe', 791),\n",
      " ('hrv', 690),\n",
      " ('ukr', 515),\n",
      " ('dan', 493)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "langList = {}\n",
    "for v in papers.itervalues():\n",
    "    for lang in v['lang']:\n",
    "        if langList.get(lang) is None:\n",
    "            langList[lang] = set([])\n",
    "        for auth in v['auth']:\n",
    "                langList[lang].add(auth)\n",
    "\n",
    "# count the lanuage used in the papers\n",
    "pprint(sorted([(k,len(v)) for (k,v) in langList.iteritems()], key=lambda x: -x[1])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chi', 0.7984509515953556),\n",
       " ('rum', 0.7478133083091381),\n",
       " ('eng', 0.7253124238106683),\n",
       " ('por', 0.6679958821863696),\n",
       " ('spa', 0.6059905017850732),\n",
       " ('rus', 0.5849271128734129),\n",
       " ('pol', 0.5642259921085655),\n",
       " ('jpn', 0.5472025628319449),\n",
       " ('fre', 0.5434637970409696),\n",
       " ('hun', 0.5153554056161257)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Count the languages with the highest cluster coefficient. Since the group with less than 1000 entities\n",
    "may have extreme stats, I would leave out the languages used less than 1000 times\n",
    "'''\n",
    "langs = {k:v for k,v in langList.iteritems() if len(v) > 1000}\n",
    "cc = {k:nx.average_clustering(G_auth,v) for k,v in langs.iteritems()}\n",
    "sorted(cc.iteritems(), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the numbers, there is no significant evidence of correlation between the size of the user group and the clustering coefficient. Considering the differences between Chinese/Rumanian and English, the culture of people using different language and the language distances, the explanation could be complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2: Co-occurence of Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# count the ocurrances of descriptions and keywords\n",
    "counter_descriptor = Counter()\n",
    "counter_keyword = Counter()\n",
    "for v in papers.itervalues():\n",
    "    counter_descriptor.update(v['description'])\n",
    "    counter_keyword.update(v['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Humans', 102582),\n",
       " ('Female', 37088),\n",
       " ('Male', 35074),\n",
       " ('Animals', 32425),\n",
       " ('Adult', 22722),\n",
       " ('Middle Aged', 18004),\n",
       " ('Aged', 12365),\n",
       " ('Adolescent', 10009),\n",
       " ('Child', 9782),\n",
       " ('Rats', 8858)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the top descriptions\n",
    "counter_descriptor.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Population', 1826),\n",
       " ('Demographic Factors', 1745),\n",
       " ('Developing Countries', 1659),\n",
       " ('Population Dynamics', 1376),\n",
       " ('Economic Factors', 1205),\n",
       " ('Developed Countries', 1122),\n",
       " ('Research Methodology', 1026),\n",
       " ('Population Characteristics', 932),\n",
       " ('Asia', 780),\n",
       " ('EXPERIMENTAL LAB STUDY', 719)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the top keywords\n",
    "counter_keyword.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_des = nx.Graph()\n",
    "for v in papers.itervalues():\n",
    "    for comb in combinations(v['description'], 2):\n",
    "        G_des.add_node(comb[0])\n",
    "        G_des.add_node(comb[1])\n",
    "        G_des.add_edge(comb[0], comb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:00.965552\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# calculate the average length of the shortest paths\n",
    "# if you need more detailed timing and performance info, use cProfile module\n",
    "t0 = datetime.now()\n",
    "\n",
    "def average_shortest_path_length(G):\n",
    "    length = 0\n",
    "    for u,v in G.edges_iter():\n",
    "        if u is not None and v is not None:\n",
    "            spl = nx.shortest_path_length(G, u, v)\n",
    "            length += spl\n",
    "    n = len(G.edges())\n",
    "    return length / float(n)\n",
    "\n",
    "avg_length = average_shortest_path_length(G_des)\n",
    "    \n",
    "t1 = datetime.now()\n",
    "print t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968995591316296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Female', 'Humans'), 32219),\n",
       " (('Humans', 'Male'), 28590),\n",
       " (('Adult', 'Humans'), 22653),\n",
       " (('Female', 'Male'), 21715),\n",
       " (('Humans', 'Middle Aged'), 17968),\n",
       " (('Adult', 'Female'), 15806),\n",
       " (('Adult', 'Male'), 15163),\n",
       " (('Male', 'Middle Aged'), 13452),\n",
       " (('Female', 'Middle Aged'), 13247),\n",
       " (('Aged', 'Humans'), 12310)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the occurance of pairs of descriptions\n",
    "counter_edge = Counter()\n",
    "for v in papers.itervalues():\n",
    "    # sort the list of description to make sure that there would not be tuples with inverse order\n",
    "    sorted_des = sorted(v['description'])\n",
    "    for e in combinations(sorted_des, 2):\n",
    "        if e:\n",
    "            counter_edge.update((e,))\n",
    "counter_edge.most_common(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# for each pair of description, run the chi square independence test\n",
    "\n",
    "def calculate_chi2(T, c1, c2):\n",
    "    table = {}\n",
    "    for u,v in c2:\n",
    "        crosstab = np.array([[0,0],[0,0]])\n",
    "        val = c2[(u,v)]\n",
    "        crosstab[1][1] += val\n",
    "        crosstab[0][1] += (c1[u]-val)\n",
    "        crosstab[1][0] += (c1[v]-val)\n",
    "        crosstab[0][0] = T - crosstab[0][1] - crosstab[1][1] - crosstab[1][0]\n",
    "        chisq = chi2_contingency(crosstab)[0]\n",
    "        table[(u,v)] = chisq\n",
    "    return table\n",
    "\n",
    "T = len(papers)\n",
    "chi2_table = calculate_chi2(T, counter_descriptor, counter_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of pairs of desriptions: 2429977\n",
      "(array([2427178,    1812,     599,     187,      81,      46,      38,\n",
      "            22,       5,       9]),\n",
      " array([  9.65653862e-11,   2.02875925e+04,   4.05751851e+04,\n",
      "         6.08627776e+04,   8.11503701e+04,   1.01437963e+05,\n",
      "         1.21725555e+05,   1.42013148e+05,   1.62300740e+05,\n",
      "         1.82588333e+05,   2.02875925e+05]))\n",
      "80% of the values fall into [0, 66.6193527632]\n"
     ]
    }
   ],
   "source": [
    "# take a look at the distribution of the chi2_table\n",
    "print 'total number of pairs of desriptions: {}'.format(len(chi2_table))\n",
    "pprint(np.histogram(chi2_table.values()))\n",
    "\n",
    "p = 80\n",
    "print '{0}% of the values fall into [0, {1}]'.format(p, np.percentile(chi2_table.values(), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 22044\n",
      "Number of edges: 484434\n"
     ]
    }
   ],
   "source": [
    "# take 67 as the threshold, select the pairs of descriptions with ch2 value greater than 67\n",
    "selected_pairs = [k for k,v in chi2_table.iteritems() if v > 67]\n",
    "\n",
    "# construct the selected graph for analysis\n",
    "G_sel = nx.Graph()\n",
    "for u,v in selected_pairs:\n",
    "    G_sel.add_nodes_from([u,v])\n",
    "    G_sel.add_edges_from([(u,v)])\n",
    "print 'Number of nodes: {}'.format(len(G_sel.nodes()))\n",
    "print 'Number of edges: {}'.format(len(G_sel.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999525219121697"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_length_sel = average_shortest_path_length(G_sel)\n",
    "avg_length_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average shortest path length does not change a lot after the pairs of descriptions with low chi square values are removed - the connections between each pair of nodes(the authors) are already strong enough, which is not exactly what I have expected. On the other hand, having a stable stats after some of the nodes and edges are removed is a sign of a stable network, indicating some attributes of a small-world network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part3: Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in training graph: 333958\n",
      "Number of edges in training graph: 535985\n",
      "Number of nodes in validation graph: 142600\n",
      "Number of edges in validation graph: 97827\n"
     ]
    }
   ],
   "source": [
    "def train_vali_split(G):\n",
    "    '''\n",
    "    parameter: the co-authorship graph\n",
    "    return: training graph and validation graph\n",
    "    split ratio: 7:3\n",
    "    '''\n",
    "    G_vali = nx.Graph()\n",
    "    vali_nodes = [n for n in G.nodes_iter() if np.random.random() <= 0.3]\n",
    "    G_vali = G.subgraph(vali_nodes)\n",
    "    G.remove_nodes_from(vali_nodes)\n",
    "    print 'Number of nodes in training graph: {}'.format(len(G.nodes()))\n",
    "    print 'Number of edges in training graph: {}'.format(len(G.edges()))    \n",
    "    print 'Number of nodes in validation graph: {}'.format(len(G_vali.nodes()))\n",
    "    print 'Number of edges in validation graph: {}'.format(len(G_vali.edges()))\n",
    "    return G, G_vali\n",
    "\n",
    "G_train, G_vali = train_vali_split(G_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change of Split Method\n",
    "\n",
    "It seems that although the nodes ratio is close to 7:3, it is not a good idea to use subgraph() to do the split, since the random selection of nodes would lead to a much less coupled graph wiht much fewer edges. This situation would lead to the underfit of the validation set, since it is less likely to have edges in the validation graph. \n",
    "\n",
    "Thankfully we have the original papers data, instead I'm going to construct the train/validation graph from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in training graph: 354681\n",
      "Number of edges in training graph: 773047\n",
      "Number of nodes in validation graph: 169446\n",
      "Number of edges in validation graph: 337784\n"
     ]
    }
   ],
   "source": [
    "def split_from_origin(papers):\n",
    "    '''\n",
    "    parameter: dictionary of paper: authors\n",
    "    return: training graph and validation graph\n",
    "    using number of co-author(s) as weight\n",
    "    split ratio: 7:3\n",
    "    '''\n",
    "    G_train = nx.Graph()\n",
    "    G_vali = nx.Graph()\n",
    "    for k,v in papers.iteritems():\n",
    "        auths = v['auth']\n",
    "        if np.random.random() <= 0.7:\n",
    "            G_train.add_nodes_from(auths)\n",
    "            for comb in combinations(auths, 2):\n",
    "                G_train.add_edge(comb[0], comb[1], weight=len(auths))\n",
    "        else:\n",
    "            G_vali.add_nodes_from(auths)\n",
    "            for comb in combinations(auths, 2):\n",
    "                G_vali.add_edge(comb[0], comb[1], weight=len(auths))\n",
    "    print 'Number of nodes in training graph: {}'.format(len(G_train.nodes()))\n",
    "    print 'Number of edges in training graph: {}'.format(len(G_train.edges()))    \n",
    "    print 'Number of nodes in validation graph: {}'.format(len(G_vali.nodes()))\n",
    "    print 'Number of edges in validation graph: {}'.format(len(G_vali.edges()))\n",
    "    return G_train, G_vali\n",
    "\n",
    "G_train, G_vali = split_from_origin(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now the train/validation graphs look much better, let's get started!\n",
    "import math\n",
    "\n",
    "def get_data(G):\n",
    "    \n",
    "    N = len(G.nodes())\n",
    "    print 'Number of nodes: {}'.format(N)\n",
    "    \n",
    "    data = {}\n",
    "    data['label'] = {}\n",
    "    flist = ['Jaccard', 'Cosine', 'Adar', 'common_neighbors', 'PageRank', 'kNN1', 'kNN2']\n",
    "    for f in flist:\n",
    "        data[f] = {}\n",
    "    \n",
    "    # personalized pagerank, setting the damping parameter as 0.8\n",
    "    # return a dictionary of node: score\n",
    "    pagerank = nx.pagerank(G, alpha=0.8, weight='weight')\n",
    "    \n",
    "    # since the possible edge set would be enourmous, we need to use previous pagerank\n",
    "    # to filter the nodes with highest score\n",
    "    N_high = N/200\n",
    "    N_candidate = N_high * (N_high-1) / 2\n",
    "    print 'Number of edges to calculate: {}'.format(N_candidate)\n",
    "    \n",
    "    nodes = dict(sorted(pagerank.iteritems(), key=lambda x: -x[1])[:N_high])\n",
    "    k = 0\n",
    "    K = 0\n",
    "    for u,v in combinations(nodes.keys(), 2):\n",
    "        \n",
    "        un = [_ for _ in nx.all_neighbors(G, u)]\n",
    "        vn = [_ for _ in nx.all_neighbors(G, v)]\n",
    "        cn = set(un) & set(vn)\n",
    "        union = set(un) | set(vn)\n",
    "        un_len = len(un)\n",
    "        vn_len = len(vn)\n",
    "        cn_len = len(cn)\n",
    "        \n",
    "        data['common_neighbors'][(u,v)] = cn_len\n",
    "        data['Jaccard'][(u,v)] = float(cn_len) / len(union)\n",
    "        data['Cosine'][(u,v)] = float(cn_len) / (un_len * vn_len)\n",
    "        \n",
    "        if cn_len == 1 or cn_len == 0:\n",
    "            data['Adar'][(u,v)] = 0\n",
    "        else:\n",
    "            data['Adar'][(u,v)] = 1.0 / math.log(cn_len)\n",
    "        \n",
    "        # the ways to calculate kNN weights are various, per se wa+wb, wa * wb\n",
    "        # even deeper (2nd level or more) connections can be taken into account\n",
    "        # for the sake of performance, I chose the 1st level calculation as weights\n",
    "        data['kNN1'][(u,v)] = (1 / math.sqrt(1 + un_len)) + (1 / math.sqrt(1 + vn_len))\n",
    "        data['kNN2'][(u,v)] = (1 / math.sqrt(1 + un_len)) * (1 / math.sqrt(1 + vn_len))\n",
    "        data['PageRank'][(u,v)] = nodes[u] * nodes[v]\n",
    "        \n",
    "        if G.has_edge(u,v) is True:\n",
    "            data['label'][(u,v)] = 1\n",
    "        else:\n",
    "            data['label'][(u,v)] = 0\n",
    "        \n",
    "        k += 1\n",
    "        if k % (N_candidate/10) == 0:\n",
    "            K += 10\n",
    "            print 'Current progress: {}%'.format(K) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 354681\n",
      "Number of edges to calculate: 1570878\n",
      "Current progress: 10%\n",
      "Current progress: 20%\n",
      "Current progress: 30%\n",
      "Current progress: 40%\n",
      "Current progress: 50%\n",
      "Current progress: 60%\n",
      "Current progress: 70%\n",
      "Current progress: 80%\n",
      "Current progress: 90%\n",
      "Current progress: 100%\n"
     ]
    }
   ],
   "source": [
    "data_train = get_data(G_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adar</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>common_neighbors</th>\n",
       "      <th>kNN1</th>\n",
       "      <th>kNN2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ARNOULD P, Abayomi A)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.442268e-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634845</td>\n",
       "      <td>0.100504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ARNOULD P, Abe H)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.279890e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462433</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ARNOULD P, Abe K)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.612973e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457368</td>\n",
       "      <td>0.041345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ARNOULD P, Abe T)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.474687e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460333</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ARNOULD P, Abolmaesumi Purang)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.243724e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591532</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Adar  Cosine  Jaccard      PageRank  \\\n",
       "(ARNOULD P, Abayomi A)              0       0        0  9.442268e-11   \n",
       "(ARNOULD P, Abe H)                  0       0        0  1.279890e-10   \n",
       "(ARNOULD P, Abe K)                  0       0        0  1.612973e-10   \n",
       "(ARNOULD P, Abe T)                  0       0        0  1.474687e-10   \n",
       "(ARNOULD P, Abolmaesumi Purang)     0       0        0  1.243724e-10   \n",
       "\n",
       "                                 common_neighbors      kNN1      kNN2  label  \n",
       "(ARNOULD P, Abayomi A)                          0  0.634845  0.100504      0  \n",
       "(ARNOULD P, Abe H)                              0  0.462433  0.043033      0  \n",
       "(ARNOULD P, Abe K)                              0  0.457368  0.041345      0  \n",
       "(ARNOULD P, Abe T)                              0  0.460333  0.042333      0  \n",
       "(ARNOULD P, Abolmaesumi Purang)                 0  0.591532  0.086066      0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to ensure the index is correct, which is crucial to the problem\n",
    "df_train = pd.DataFrame(data_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 169446\n",
      "Number of edges to calculate: 358281\n",
      "Current progress: 10%\n",
      "Current progress: 20%\n",
      "Current progress: 30%\n",
      "Current progress: 40%\n",
      "Current progress: 50%\n",
      "Current progress: 60%\n",
      "Current progress: 70%\n",
      "Current progress: 80%\n",
      "Current progress: 90%\n",
      "Current progress: 100%\n"
     ]
    }
   ],
   "source": [
    "data_vali = get_data(G_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adar</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>common_neighbors</th>\n",
       "      <th>kNN1</th>\n",
       "      <th>kNN2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Abe T, Akbulut H)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.528048e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387298</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Abe T, BONNAL J)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.470430e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430611</td>\n",
       "      <td>0.038925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Abe T, Berg T)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.673243e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406450</td>\n",
       "      <td>0.035806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Abe T, Bird E D)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.742763e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347317</td>\n",
       "      <td>0.028172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Abe T, Bloom S R)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.635237e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321550</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Adar  Cosine  Jaccard      PageRank  common_neighbors  \\\n",
       "(Abe T, Akbulut H)     0       0        0  5.528048e-10                 0   \n",
       "(Abe T, BONNAL J)      0       0        0  5.470430e-10                 0   \n",
       "(Abe T, Berg T)        0       0        0  5.673243e-10                 0   \n",
       "(Abe T, Bird E D)      0       0        0  5.742763e-10                 0   \n",
       "(Abe T, Bloom S R)     0       0        0  9.635237e-10                 0   \n",
       "\n",
       "                        kNN1      kNN2  label  \n",
       "(Abe T, Akbulut H)  0.387298  0.033333      0  \n",
       "(Abe T, BONNAL J)   0.430611  0.038925      0  \n",
       "(Abe T, Berg T)     0.406450  0.035806      0  \n",
       "(Abe T, Bird E D)   0.347317  0.028172      0  \n",
       "(Abe T, Bloom S R)  0.321550  0.024845      0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vali = pd.DataFrame(data_vali)\n",
    "df_vali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv', index=False)\n",
    "df_vali.to_csv('validate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>7 minutes 53 seconds 98 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.1.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>light</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>1.56 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.11</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ------------------------------------\n",
       "H2O cluster uptime:             7 minutes 53 seconds 98 milliseconds\n",
       "H2O cluster version:            3.8.1.3\n",
       "H2O cluster name:               light\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  1.56 GB\n",
       "H2O cluster total cores:        4\n",
       "H2O cluster allowed cores:      4\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.11\n",
       "------------------------------  ------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  Adar</th><th style=\"text-align: right;\">  Cosine</th><th style=\"text-align: right;\">  Jaccard</th><th style=\"text-align: right;\">   PageRank</th><th style=\"text-align: right;\">  common_neighbors</th><th style=\"text-align: right;\">    kNN1</th><th style=\"text-align: right;\">     kNN2</th><th style=\"text-align: right;\">  label</th></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">9.44227e-11</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.634845</td><td style=\"text-align: right;\">0.100504 </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1.27989e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.462433</td><td style=\"text-align: right;\">0.0430331</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1.61297e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.457368</td><td style=\"text-align: right;\">0.0413449</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1.47469e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.460333</td><td style=\"text-align: right;\">0.0423334</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1.24372e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.591532</td><td style=\"text-align: right;\">0.0860663</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "basedir = os.getcwd()\n",
    "fr_train = h2o.import_file(path=basedir+\"/train.csv\")\n",
    "fr_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  Adar</th><th style=\"text-align: right;\">  Cosine</th><th style=\"text-align: right;\">  Jaccard</th><th style=\"text-align: right;\">   PageRank</th><th style=\"text-align: right;\">  common_neighbors</th><th style=\"text-align: right;\">    kNN1</th><th style=\"text-align: right;\">     kNN2</th><th style=\"text-align: right;\">  label</th></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">5.52805e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.387298</td><td style=\"text-align: right;\">0.0333333</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">5.47043e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.430611</td><td style=\"text-align: right;\">0.0389249</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">5.67324e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.40645 </td><td style=\"text-align: right;\">0.0358057</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">5.74276e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.347317</td><td style=\"text-align: right;\">0.0281718</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">9.63524e-10</td><td style=\"text-align: right;\">                 0</td><td style=\"text-align: right;\">0.32155 </td><td style=\"text-align: right;\">0.0248452</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vali = h2o.import_file(path=basedir+\"/validate.csv\")\n",
    "fr_vali.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  GBM_model_python_1458712020197_2\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>100.0</td>\n",
       "<td>40353.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>28.0</td>\n",
       "<td>32.0</td>\n",
       "<td>29.36</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    100                40353                  5            5            5             28            32            29.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.491430863128\n",
      "R^2: -0.965723452513\n",
      "LogLoss: 2.38680414851\n",
      "AUC: 0.998721217075\n",
      "Gini: 0.997442434149\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.00238006530015: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>1551478.0</td>\n",
       "<td>16225.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (16225.0/1567703.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>9875.0</td>\n",
       "<td>1557829.0</td>\n",
       "<td>0.0063</td>\n",
       "<td> (9875.0/1567704.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1561353.0</td>\n",
       "<td>1574054.0</td>\n",
       "<td>0.0083</td>\n",
       "<td> (26100.0/3135407.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0            1            Error    Rate\n",
       "-----  -----------  -----------  -------  -------------------\n",
       "0      1.55148e+06  16225        0.0103   (16225.0/1567703.0)\n",
       "1      9875         1.55783e+06  0.0063   (9875.0/1567704.0)\n",
       "Total  1.56135e+06  1.57405e+06  0.0083   (26100.0/3135407.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0023801</td>\n",
       "<td>0.9916925</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0019017</td>\n",
       "<td>0.9934527</td>\n",
       "<td>273.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0035089</td>\n",
       "<td>0.9914199</td>\n",
       "<td>185.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0023801</td>\n",
       "<td>0.9916757</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.0089128</td>\n",
       "<td>0.9999138</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0004628</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.0089128</td>\n",
       "<td>0.9999553</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.0023801</td>\n",
       "<td>0.9833595</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0025958</td>\n",
       "<td>0.9907540</td>\n",
       "<td>232.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.00238007   0.991693  246\n",
       "max f2                      0.00190171   0.993453  273\n",
       "max f0point5                0.00350894   0.99142   185\n",
       "max accuracy                0.00238007   0.991676  246\n",
       "max precision               0.00891278   0.999914  0\n",
       "max recall                  0.000462833  1         394\n",
       "max specificity             0.00891278   0.999955  0\n",
       "max absolute_MCC            0.00238007   0.98336   246\n",
       "max min_per_class_accuracy  0.00259576   0.990754  232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.20 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100994</td>\n",
       "<td>0.0028920</td>\n",
       "<td>97.8302515</td>\n",
       "<td>97.8302515</td>\n",
       "<td>0.1977309</td>\n",
       "<td>0.1977309</td>\n",
       "<td>0.9880315</td>\n",
       "<td>0.9880315</td>\n",
       "<td>9683.0251527</td>\n",
       "<td>9683.0251527</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200187</td>\n",
       "<td>0.0009349</td>\n",
       "<td>0.7620558</td>\n",
       "<td>49.7329250</td>\n",
       "<td>0.0015402</td>\n",
       "<td>0.1005183</td>\n",
       "<td>0.0075591</td>\n",
       "<td>0.9955906</td>\n",
       "<td>-23.7944206</td>\n",
       "<td>4873.2925044</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0331382</td>\n",
       "<td>0.0004982</td>\n",
       "<td>0.0720216</td>\n",
       "<td>30.0721452</td>\n",
       "<td>0.0001456</td>\n",
       "<td>0.0607807</td>\n",
       "<td>0.0009449</td>\n",
       "<td>0.9965354</td>\n",
       "<td>-92.7978351</td>\n",
       "<td>2907.2145152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0439003</td>\n",
       "<td>0.0004974</td>\n",
       "<td>0.0</td>\n",
       "<td>22.6999737</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0458803</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9965354</td>\n",
       "<td>-100.0</td>\n",
       "<td>2169.9973725</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526425</td>\n",
       "<td>0.0004827</td>\n",
       "<td>0.0</td>\n",
       "<td>18.9302326</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0382611</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9965354</td>\n",
       "<td>-100.0</td>\n",
       "<td>1793.0232638</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1204186</td>\n",
       "<td>0.0004665</td>\n",
       "<td>0.0278824</td>\n",
       "<td>8.2912841</td>\n",
       "<td>0.0000564</td>\n",
       "<td>0.0167580</td>\n",
       "<td>0.0018898</td>\n",
       "<td>0.9984252</td>\n",
       "<td>-97.2117553</td>\n",
       "<td>729.1284111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1518756</td>\n",
       "<td>0.0004638</td>\n",
       "<td>0.0</td>\n",
       "<td>6.5739682</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0132871</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9984252</td>\n",
       "<td>-100.0</td>\n",
       "<td>557.3968163</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3190273</td>\n",
       "<td>0.0004631</td>\n",
       "<td>0.0018843</td>\n",
       "<td>3.1305788</td>\n",
       "<td>0.0000038</td>\n",
       "<td>0.0063274</td>\n",
       "<td>0.0003150</td>\n",
       "<td>0.9987402</td>\n",
       "<td>-99.8115720</td>\n",
       "<td>213.0578768</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.5205089</td>\n",
       "<td>0.0004628</td>\n",
       "<td>0.0062529</td>\n",
       "<td>1.9211967</td>\n",
       "<td>0.0000126</td>\n",
       "<td>0.0038831</td>\n",
       "<td>0.0012598</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.3747109</td>\n",
       "<td>92.1196689</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.7256331</td>\n",
       "<td>0.0004620</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3781070</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027854</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>37.8107013</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.9983461</td>\n",
       "<td>0.0004603</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0016566</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0020245</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.1656592</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004389</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0020212</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100994                   0.00289197         97.8303     97.8303            0.197731         0.197731                    0.988031        0.988031                   9683.03   9683.03\n",
       "    2        0.0200187                   0.000934892        0.762056    49.7329            0.00154024       0.100518                    0.00755906      0.995591                   -23.7944  4873.29\n",
       "    3        0.0331382                   0.000498151        0.0720216   30.0721            0.000145567      0.0607807                   0.000944882     0.996535                   -92.7978  2907.21\n",
       "    4        0.0439003                   0.000497411        0           22.7               0                0.0458803                   0               0.996535                   -100      2170\n",
       "    5        0.0526425                   0.000482719        0           18.9302            0                0.0382611                   0               0.996535                   -100      1793.02\n",
       "    6        0.120419                    0.000466498        0.0278824   8.29128            5.6355e-05       0.016758                    0.00188976      0.998425                   -97.2118  729.128\n",
       "    7        0.151876                    0.000463814        0           6.57397            0                0.0132871                   0               0.998425                   -100      557.397\n",
       "    8        0.319027                    0.000463125        0.00188428  3.13058            3.80844e-06      0.00632741                  0.000314961     0.99874                    -99.8116  213.058\n",
       "    9        0.520509                    0.000462833        0.00625289  1.9212             1.26381e-05      0.00388305                  0.00125984      1                          -99.3747  92.1197\n",
       "    10       0.725633                    0.00046196         0           1.37811            0                0.00278538                  0               1                          -100      37.8107\n",
       "    11       0.998346                    0.000460337        0           1.00166            0                0.00202451                  0               1                          -100      0.165659\n",
       "    12       1                           0.000438946        0           1                  0                0.00202116                  0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.00406798125534\n",
      "R^2: 0.0131232075352\n",
      "LogLoss: 0.0203166520275\n",
      "AUC: 0.997963304709\n",
      "Gini: 0.995926609418\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.00882852677271: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>356652.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0004</td>\n",
       "<td> (146.0/356798.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>144.0</td>\n",
       "<td>1339.0</td>\n",
       "<td>0.0971</td>\n",
       "<td> (144.0/1483.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>356796.0</td>\n",
       "<td>1485.0</td>\n",
       "<td>0.0008</td>\n",
       "<td> (290.0/358281.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1     Error    Rate\n",
       "-----  ------  ----  -------  ----------------\n",
       "0      356652  146   0.0004   (146.0/356798.0)\n",
       "1      144     1339  0.0971   (144.0/1483.0)\n",
       "Total  356796  1485  0.0008   (290.0/358281.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0088285</td>\n",
       "<td>0.9022911</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0085231</td>\n",
       "<td>0.9168193</td>\n",
       "<td>22.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0088497</td>\n",
       "<td>0.9082045</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0088285</td>\n",
       "<td>0.9991906</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.0089128</td>\n",
       "<td>0.9340747</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0004638</td>\n",
       "<td>1.0</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.0089128</td>\n",
       "<td>0.9997674</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.0088285</td>\n",
       "<td>0.9018849</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0047389</td>\n",
       "<td>0.9885367</td>\n",
       "<td>79.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.00882853   0.902291  8\n",
       "max f2                      0.00852306   0.916819  22\n",
       "max f0point5                0.00884966   0.908204  5\n",
       "max accuracy                0.00882853   0.999191  8\n",
       "max precision               0.00891278   0.934075  0\n",
       "max recall                  0.000463814  1         197\n",
       "max specificity             0.00891278   0.999767  0\n",
       "max absolute_MCC            0.00882853   0.901885  8\n",
       "max min_per_class_accuracy  0.00473891   0.988537  79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.41 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100284</td>\n",
       "<td>0.0055700</td>\n",
       "<td>97.9009226</td>\n",
       "<td>97.9009226</td>\n",
       "<td>0.4052324</td>\n",
       "<td>0.4052324</td>\n",
       "<td>0.9817937</td>\n",
       "<td>0.9817937</td>\n",
       "<td>9690.0922581</td>\n",
       "<td>9690.0922581</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0201015</td>\n",
       "<td>0.0045264</td>\n",
       "<td>0.8032986</td>\n",
       "<td>49.2442543</td>\n",
       "<td>0.0033250</td>\n",
       "<td>0.2038323</td>\n",
       "<td>0.0080917</td>\n",
       "<td>0.9898854</td>\n",
       "<td>-19.6701436</td>\n",
       "<td>4824.4254284</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0459751</td>\n",
       "<td>0.0010618</td>\n",
       "<td>0.2345554</td>\n",
       "<td>21.6629096</td>\n",
       "<td>0.0009709</td>\n",
       "<td>0.0896673</td>\n",
       "<td>0.0060688</td>\n",
       "<td>0.9959541</td>\n",
       "<td>-76.5444618</td>\n",
       "<td>2066.2909649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0514959</td>\n",
       "<td>0.0010598</td>\n",
       "<td>0.0</td>\n",
       "<td>19.3404579</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0800542</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9959541</td>\n",
       "<td>-100.0</td>\n",
       "<td>1834.0457872</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1468512</td>\n",
       "<td>0.0010533</td>\n",
       "<td>0.0</td>\n",
       "<td>6.7820627</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0280724</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9959541</td>\n",
       "<td>-100.0</td>\n",
       "<td>578.2062716</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1790131</td>\n",
       "<td>0.0009511</td>\n",
       "<td>0.0</td>\n",
       "<td>5.5635818</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0230288</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9959541</td>\n",
       "<td>-100.0</td>\n",
       "<td>456.3581829</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2008675</td>\n",
       "<td>0.0004827</td>\n",
       "<td>0.0617093</td>\n",
       "<td>4.9649788</td>\n",
       "<td>0.0002554</td>\n",
       "<td>0.0205511</td>\n",
       "<td>0.0013486</td>\n",
       "<td>0.9973028</td>\n",
       "<td>-93.8290666</td>\n",
       "<td>396.4978835</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.5254256</td>\n",
       "<td>0.0004669</td>\n",
       "<td>0.0041552</td>\n",
       "<td>1.9006524</td>\n",
       "<td>0.0000172</td>\n",
       "<td>0.0078672</td>\n",
       "<td>0.0013486</td>\n",
       "<td>0.9986514</td>\n",
       "<td>-99.5844757</td>\n",
       "<td>90.0652409</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.8418002</td>\n",
       "<td>0.0004644</td>\n",
       "<td>0.0021314</td>\n",
       "<td>1.1871294</td>\n",
       "<td>0.0000088</td>\n",
       "<td>0.0049138</td>\n",
       "<td>0.0006743</td>\n",
       "<td>0.9993257</td>\n",
       "<td>-99.7868638</td>\n",
       "<td>18.7129379</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.9138972</td>\n",
       "<td>0.0004638</td>\n",
       "<td>0.0093528</td>\n",
       "<td>1.0942150</td>\n",
       "<td>0.0000387</td>\n",
       "<td>0.0045292</td>\n",
       "<td>0.0006743</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.0647205</td>\n",
       "<td>9.4214982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004571</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041392</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100284                   0.00557003         97.9009     97.9009            0.405232         0.405232                    0.981794        0.981794                   9690.09   9690.09\n",
       "    2        0.0201015                   0.00452636         0.803299    49.2443            0.00332502       0.203832                    0.00809171      0.989885                   -19.6701  4824.43\n",
       "    3        0.0459751                   0.00106183         0.234555    21.6629            0.000970874      0.0896673                   0.00606878      0.995954                   -76.5445  2066.29\n",
       "    4        0.0514959                   0.00105983         0           19.3405            0                0.0800542                   0               0.995954                   -100      1834.05\n",
       "    5        0.146851                    0.00105328         0           6.78206            0                0.0280724                   0               0.995954                   -100      578.206\n",
       "    6        0.179013                    0.000951127        0           5.56358            0                0.0230288                   0               0.995954                   -100      456.358\n",
       "    7        0.200867                    0.000482719        0.0617093   4.96498            0.000255428      0.0205511                   0.00134862      0.997303                   -93.8291  396.498\n",
       "    8        0.525426                    0.000466885        0.00415524  1.90065            1.71994e-05      0.0078672                   0.00134862      0.998651                   -99.5845  90.0652\n",
       "    9        0.8418                      0.000464367        0.00213136  1.18713            8.82215e-06      0.00491378                  0.000674309     0.999326                   -99.7869  18.7129\n",
       "    10       0.913897                    0.000463814        0.00935279  1.09421            3.87132e-05      0.00452918                  0.000674309     1                          -99.0647  9.4215\n",
       "    11       1                           0.000457076        0           1                  0                0.00413921                  0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_MSE</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_AUC</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:56:21</td>\n",
       "<td> 0.058 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4979831</td>\n",
       "<td>3.1030538</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4999998</td>\n",
       "<td>0.0041266</td>\n",
       "<td>0.0276948</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9958608</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:56:27</td>\n",
       "<td> 6.351 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4979437</td>\n",
       "<td>3.0933879</td>\n",
       "<td>0.9974892</td>\n",
       "<td>72.0553396</td>\n",
       "<td>0.0106088</td>\n",
       "<td>0.0041261</td>\n",
       "<td>0.0275812</td>\n",
       "<td>0.9950889</td>\n",
       "<td>72.7052913</td>\n",
       "<td>0.0008625</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:56:41</td>\n",
       "<td>19.677 sec</td>\n",
       "<td>9.0</td>\n",
       "<td>0.4976146</td>\n",
       "<td>3.0193144</td>\n",
       "<td>0.9975125</td>\n",
       "<td>93.9624102</td>\n",
       "<td>0.0104136</td>\n",
       "<td>0.0041225</td>\n",
       "<td>0.0267308</td>\n",
       "<td>0.9962087</td>\n",
       "<td>70.8427796</td>\n",
       "<td>0.0008625</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:57:14</td>\n",
       "<td>52.389 sec</td>\n",
       "<td>28.0</td>\n",
       "<td>0.4967236</td>\n",
       "<td>2.8615534</td>\n",
       "<td>0.9975979</td>\n",
       "<td>95.8447957</td>\n",
       "<td>0.0099081</td>\n",
       "<td>0.0041139</td>\n",
       "<td>0.0250174</td>\n",
       "<td>0.9973811</td>\n",
       "<td>65.5954657</td>\n",
       "<td>0.0008485</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:58:31</td>\n",
       "<td> 2 min 10.060 sec</td>\n",
       "<td>75.0</td>\n",
       "<td>0.4936848</td>\n",
       "<td>2.5371535</td>\n",
       "<td>0.9986898</td>\n",
       "<td>98.4878459</td>\n",
       "<td>0.0085265</td>\n",
       "<td>0.0040872</td>\n",
       "<td>0.0217288</td>\n",
       "<td>0.9978231</td>\n",
       "<td>97.8192477</td>\n",
       "<td>0.0008094</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-03-22 22:59:33</td>\n",
       "<td> 3 min 11.958 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.4914309</td>\n",
       "<td>2.3868041</td>\n",
       "<td>0.9987212</td>\n",
       "<td>97.8302515</td>\n",
       "<td>0.0083243</td>\n",
       "<td>0.0040680</td>\n",
       "<td>0.0203167</td>\n",
       "<td>0.9979633</td>\n",
       "<td>97.9009226</td>\n",
       "<td>0.0008094</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_MSE    training_logloss    training_AUC    training_lift    training_classification_error    validation_MSE    validation_logloss    validation_AUC    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  --------------  ------------------  --------------  ---------------  -------------------------------  ----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2016-03-22 22:56:21  0.058 sec         0                  0.497983        3.10305             0.5             1                0.5                              0.00412656        0.0276948             0.5               1                  0.995861\n",
       "    2016-03-22 22:56:27  6.351 sec         1                  0.497944        3.09339             0.997489        72.0553          0.0106088                        0.0041261         0.0275812             0.995089          72.7053            0.000862452\n",
       "    2016-03-22 22:56:41  19.677 sec        9                  0.497615        3.01931             0.997512        93.9624          0.0104136                        0.0041225         0.0267308             0.996209          70.8428            0.000862452\n",
       "    2016-03-22 22:57:14  52.389 sec        28                 0.496724        2.86155             0.997598        95.8448          0.00990812                       0.00411387        0.0250174             0.997381          65.5955            0.000848496\n",
       "    2016-03-22 22:58:31  2 min 10.060 sec  75                 0.493685        2.53715             0.99869         98.4878          0.00852648                       0.00408718        0.0217288             0.997823          97.8192            0.000809421\n",
       "    2016-03-22 22:59:33  3 min 11.958 sec  100                0.491431        2.3868              0.998721        97.8303          0.00832428                       0.00406798        0.0203167             0.997963          97.9009            0.000809421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Jaccard</td>\n",
       "<td>32645676.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9871298</td></tr>\n",
       "<tr><td>Adar</td>\n",
       "<td>241428.3125000</td>\n",
       "<td>0.0073954</td>\n",
       "<td>0.0073002</td></tr>\n",
       "<tr><td>PageRank</td>\n",
       "<td>70037.6875000</td>\n",
       "<td>0.0021454</td>\n",
       "<td>0.0021178</td></tr>\n",
       "<tr><td>kNN1</td>\n",
       "<td>57721.3164062</td>\n",
       "<td>0.0017681</td>\n",
       "<td>0.0017454</td></tr>\n",
       "<tr><td>Cosine</td>\n",
       "<td>32514.1152344</td>\n",
       "<td>0.0009960</td>\n",
       "<td>0.0009832</td></tr>\n",
       "<tr><td>kNN2</td>\n",
       "<td>23931.5761719</td>\n",
       "<td>0.0007331</td>\n",
       "<td>0.0007236</td></tr>\n",
       "<tr><td>common_neighbors</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "Jaccard           3.26457e+07            1                    0.98713\n",
       "Adar              241428                 0.00739541           0.00730023\n",
       "PageRank          70037.7                0.00214539           0.00211778\n",
       "kNN1              57721.3                0.00176812           0.00174536\n",
       "Cosine            32514.1                0.00099597           0.000983152\n",
       "kNN2              23931.6                0.00073307           0.000723636\n",
       "common_neighbors  0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fr_train['label'] = fr_train['label'].asfactor()\n",
    "fr_vali['label'] = fr_vali['label'].asfactor()\n",
    "\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(distribution='bernoulli',\n",
    "                                   ntrees=100,\n",
    "                                   max_depth=5,\n",
    "                                   balance_classes=True,\n",
    "                                   learn_rate=0.01)\n",
    "\n",
    "gbm.train(x=fr_train.columns[:-1],\n",
    "          y='label', \n",
    "          training_frame=fr_train,\n",
    "          validation_frame=fr_vali)\n",
    "\n",
    "gbm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link prediction result:\n",
    "\n",
    "Without feature engineering and grid search, the model is able to provide prediction with accuracy of 99.92% and AUC of 99.79% which proves that the choices of the features are correct! Even facing the sparsity of social network, this model ahieve its goal with basic attributes calculations and even 'out-of-date' PageRank algorithm. On this dataset, I would say the link prediction problem is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
