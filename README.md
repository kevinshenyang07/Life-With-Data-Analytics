# Notes and Projects

Hi, its kevin.

Data Science is huge yet fascinating, let's see how far we can go.

Never stop learning, get better everyday.

**Notes:**

The articles that I translated in my spare time. Hope more people in China can know how data science is evolving all around the world.

[A Sneak Peek Into Optimizelyâ€™s First Industry Benchmark Report](https://github.com/kevinshenyang07/notes-and-projects/blob/gh-pages/notes/A%20Sneak%20Peek%20Into%20Optimizely%E2%80%99s%20First%20Industry%20Benchmark%20Report.pdf)

[Choose Boring Technology](https://github.com/kevinshenyang07/notes-and-projects/blob/gh-pages/notes/Choose%20Boring%20Technology.pdf)

[Creating a Data-Driven Organization- Two Years On](https://github.com/kevinshenyang07/notes-and-projects/blob/gh-pages/notes/Creating%20a%20Data-Driven%20Organization-%20Two%20Years%20On.pdf)

[CS183C-11-Technology-enabled Blitzscaling By Patrick Collison](https://github.com/kevinshenyang07/notes-and-projects/blob/gh-pages/notes/CS183C-11-Technology-enabled%20Blitzscaling.md)

**Projects:**

[Give Me Some Credit](https://github.com/kevinshenyang07/notes-and-projects/tree/gh-pages/projects/Give_Me_Some_Credit/Give_Me_Some_Credit.ipynb)

Used Random Forest and Gradient Boosting Trees to predict serious delinquencies in next two years. Tuned parameters by grid search cross-validation and achieved the model AUC of 0.865, followed by prevention cost analysis. The model already reaches Kaggle bechmark with minimum feature engineering.

[Wells Fargo Text Analysis](https://github.com/kevinshenyang07/notes-and-projects/blob/gh-pages/projects/Text_Anlysis_Wells_Fargo/Hashtags_TFIDF_KMeans_LDA_Word2Vec.ipynb)

Cleaned the tweets from scratch, used K-means Clustering, LDA Topic Model and Word2Vec to discover certain groupings and investigate differences of topics about each bank.

[Geo-austin](https://github.com/kevinshenyang07/notes-and-projects/tree/gh-pages/projects/Open_Street_Map_Austin)

Clean and parse large XML file provided by Open Street Map into JSON, explore and aggregate the data in MongoDB and visualize it with tableau.

[Prediction Service Demo](https://github.com/kevinshenyang07/notes-and-projects/tree/gh-pages/projects/Prediction_Service_Demo)

With Yelp open dataset, used Flask and cherrypy to build a minimally viable web service, used Spark and Alternating Least Square to process data and provide city-wise recommendations on Yelp businesses.

[Define Data Analyst](https://github.com/kevinshenyang07/notes-and-projects/tree/gh-pages/projects/Define_Data_Analyst)

Use indeed API to get the metadata of positions with keyword "data analyst", get the contents of original job pages and build corpus based on the job description and requirements. Still in progress...